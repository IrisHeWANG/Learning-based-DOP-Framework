{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiezhq/.wanghe_env/lib/python3.7/site-packages/torch_sparse/tensor.py:46: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  index = mat.nonzero()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import copy\n",
    "import pandas as pd\n",
    "import xlwt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_nodes = 5\n",
    "num_edges = 6\n",
    "n = 100\n",
    "m = 80\n",
    "k = 16\n",
    "train_num = 1000\n",
    "test_num = 100\n",
    "num_layers = 50\n",
    "nnz = 8\n",
    "\n",
    "#less nnz =5; m = 50; k = 10\n",
    "\n",
    "def metropolis(adjacency_matrix):\n",
    "    num_of_nodes = adjacency_matrix.shape[0]\n",
    "    metropolis=np.zeros((num_of_nodes,num_of_nodes))\n",
    "    for i in range(num_of_nodes):\n",
    "        for j in range(num_of_nodes):\n",
    "            if adjacency_matrix[i,j]==1:\n",
    "                d_i = np.sum(adjacency_matrix[i,:])\n",
    "                d_j = np.sum(adjacency_matrix[j,:])\n",
    "                metropolis[i,j]=1/(1+max(d_i,d_j))\n",
    "        metropolis[i,i]=1-sum(metropolis[i,:])\n",
    "    return metropolis\n",
    "\n",
    "class SynDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "        self.A = []; \n",
    "        self.y = []; \n",
    "        self.x_true = []\n",
    "        self.pyg_data=[]\n",
    "        self.process()\n",
    "        \n",
    "        \n",
    "    def gen_func(self, num_of_nodes, n, m, k):\n",
    "        A_all = np.random.randn(m, n)\n",
    "        x = np.random.randn(n)\n",
    "        x_norm = 0\n",
    "\n",
    "        while(x_norm < 1e-2):\n",
    "            x_mask = np.random.rand(n)\n",
    "            x_mask[x_mask < 1 - nnz/100] = 0\n",
    "            x_mask[x_mask > 0] = 1\n",
    "            x_norm = np.linalg.norm(x * x_mask)\n",
    "\n",
    "        x = x * x_mask\n",
    "        x = x/np.linalg.norm(x)\n",
    "        \n",
    "        SNR_db = 50\n",
    "        SNR = 10**(SNR_db/10)\n",
    "        \n",
    "        noise = np.random.randn(m) * np.sqrt(1/SNR)\n",
    "        y_all = A_all@x + noise\n",
    "\n",
    "        A = np.zeros((num_of_nodes, k , n))\n",
    "        y = np.zeros((num_of_nodes, k))\n",
    "        for ii in range(num_of_nodes):\n",
    "            start = (k*ii) % m; end = (k*(ii+1) )%m\n",
    "            if(start > end):\n",
    "                A[ii,:,:] = np.concatenate((A_all[start:,:],A_all[:end,:]), axis = 0)\n",
    "                y[ii,:] = np.concatenate((np.expand_dims(y_all[start:], axis = 0), \n",
    "                                          np.expand_dims(y_all[:end], axis = 0)), axis = 1)\n",
    "            else:\n",
    "                A[ii,:,:] = A_all[start:end,:]\n",
    "                y[ii,:] = np.expand_dims(y_all[start:end], axis = 0)\n",
    "                \n",
    "        x = np.expand_dims(x, axis = 0)\n",
    "        x = x.repeat(num_of_nodes, axis = 0)\n",
    "        \n",
    "        return A, y, x\n",
    "\n",
    "    def gen_graph(self, num_of_nodes, num_of_edges, directed=False, add_self_loops=True):\n",
    "        G = nx.gnm_random_graph(num_of_nodes, num_of_edges, directed=directed)\n",
    "        k = 0\n",
    "        while (nx.is_strongly_connected(G) if directed else nx.is_connected(G)) == False:\n",
    "            G = nx.gnm_random_graph(num_of_nodes, num_of_edges, directed=directed)\n",
    "            k += 1\n",
    "        # print(\"Check if connected: \", nx.is_connected(G))\n",
    "        # nx.draw(G)\n",
    "        \n",
    "        edge_index = from_networkx(G).edge_index\n",
    "        adj = nx.to_numpy_matrix(G)\n",
    "        return G, adj,edge_index\n",
    "        \n",
    "    def process(self):\n",
    "        _, adj,edge_index = self.gen_graph(num_nodes, num_edges)\n",
    "        self.edge_index = edge_index\n",
    "        W = metropolis(adj)\n",
    "        self.W = [torch.tensor(W, dtype = torch.float)] * self.samples\n",
    "        \n",
    "        \n",
    "        for ii in range(self.samples):\n",
    "            A, y, x_true = self.gen_func(num_nodes, n, m, k)\n",
    "            self.A.append(torch.tensor(A, dtype = torch.float) ); \n",
    "            self.y.append(torch.tensor(y, dtype = torch.float) ); \n",
    "            self.x_true.append(torch.tensor(x_true, dtype = torch.float) )\n",
    "            \n",
    "            edge_weight=torch.tensor(W,dtype=torch.float)\n",
    "            self.pyg_data.append(Data(edge_weight=SparseTensor.from_dense(edge_weight)))        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.W[idx], self.A[idx], self.y[idx], self.x_true[idx], self.pyg_data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of graphs in the dataset\"\"\"\n",
    "        return len(self.A)\n",
    "    \n",
    "    \n",
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    W, A, y, x_true, pyg_data = map(list, zip(*samples))\n",
    "    W = torch.stack(W)\n",
    "    A = torch.stack(A)\n",
    "    y = torch.stack(y)\n",
    "    x_true = torch.stack(x_true)\n",
    "    pyg_data = Batch.from_data_list(pyg_data)\n",
    "    return W, A, y, x_true, pyg_data\n",
    "class MetropolisConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super(MetropolisConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "\n",
    "    def forward(self, x, pyg_data):\n",
    "        (B, N, D)=x.shape\n",
    "        out = self.propagate(x=x.view(-1,D), edge_index=pyg_data.edge_weight, node_dim=-1)\n",
    "        return out.view(B,N,D)\n",
    "\n",
    "    def message_and_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "def step_loss(gamma,x, y):\n",
    "    #gamma = 0.75\n",
    "    n_steps = x.shape[0]\n",
    "    #print(n_steps)\n",
    "    di = torch.ones((n_steps)) * gamma\n",
    "    power = torch.tensor(range(n_steps, 0, -1))\n",
    "    gamma_a = di ** power\n",
    "    gamma_a = gamma_a.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    y = torch.unsqueeze(y, axis = 0)\n",
    "    ele_loss = gamma_a * (x - y) **2\n",
    "    #print(ele_loss.shape)\n",
    "    #print(torch.mean(ele_loss,  (1,2,3) ))\n",
    "    loss = torch.mean(ele_loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "train_data = SynDataset(train_num)\n",
    "val_data = SynDataset(test_num)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "val_loader = DataLoader(val_data, batch_size=100, shuffle=False, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN-PGEXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007084578264766606 tensor(0.0093, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "0.00012178569477327983 tensor(0.0041, grad_fn=<SelectBackward>) tensor(-0.0008, grad_fn=<SelectBackward>)\n",
      "8.811488123683375e-05 tensor(0.0021, grad_fn=<SelectBackward>) tensor(0.0001, grad_fn=<SelectBackward>)\n",
      "6.656960260897904e-05 tensor(0.0006, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "5.601191321602528e-05 tensor(0.0014, grad_fn=<SelectBackward>) tensor(0.0012, grad_fn=<SelectBackward>)\n",
      "4.8075003405756433e-05 tensor(0.0011, grad_fn=<SelectBackward>) tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "4.424967221439147e-05 tensor(0.0008, grad_fn=<SelectBackward>) tensor(0.0014, grad_fn=<SelectBackward>)\n",
      "4.736732535093324e-05 tensor(0.0011, grad_fn=<SelectBackward>) tensor(0.0018, grad_fn=<SelectBackward>)\n",
      "4.387440219488781e-05 tensor(0.0010, grad_fn=<SelectBackward>) tensor(0.0017, grad_fn=<SelectBackward>)\n",
      "4.206252572203084e-05 tensor(0.0009, grad_fn=<SelectBackward>) tensor(0.0017, grad_fn=<SelectBackward>)\n",
      "4.1159131001222704e-05 tensor(0.0008, grad_fn=<SelectBackward>) tensor(0.0016, grad_fn=<SelectBackward>)\n",
      "4.010802911125211e-05 tensor(0.0008, grad_fn=<SelectBackward>) tensor(0.0016, grad_fn=<SelectBackward>)\n",
      "3.940199962926272e-05 tensor(0.0007, grad_fn=<SelectBackward>) tensor(0.0016, grad_fn=<SelectBackward>)\n",
      "3.887473008035158e-05 tensor(0.0006, grad_fn=<SelectBackward>) tensor(0.0015, grad_fn=<SelectBackward>)\n",
      "3.829265483545896e-05 tensor(0.0005, grad_fn=<SelectBackward>) tensor(0.0015, grad_fn=<SelectBackward>)\n",
      "3.754758029117511e-05 tensor(0.0004, grad_fn=<SelectBackward>) tensor(0.0014, grad_fn=<SelectBackward>)\n",
      "3.677344636798807e-05 tensor(0.0003, grad_fn=<SelectBackward>) tensor(0.0014, grad_fn=<SelectBackward>)\n",
      "3.608696351875551e-05 tensor(0.0002, grad_fn=<SelectBackward>) tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "3.487628316634073e-05 tensor(9.9192e-05, grad_fn=<SelectBackward>) tensor(0.0012, grad_fn=<SelectBackward>)\n",
      "3.387783237940312e-05 tensor(3.6122e-05, grad_fn=<SelectBackward>) tensor(0.0011, grad_fn=<SelectBackward>)\n",
      "3.409189872627394e-05 tensor(0.0003, grad_fn=<SelectBackward>) tensor(0.0014, grad_fn=<SelectBackward>)\n",
      "3.294807595466409e-05 tensor(1.5598e-05, grad_fn=<SelectBackward>) tensor(0.0011, grad_fn=<SelectBackward>)\n",
      "3.2119203865477175e-05 tensor(2.6649e-05, grad_fn=<SelectBackward>) tensor(0.0010, grad_fn=<SelectBackward>)\n",
      "3.149933712620623e-05 tensor(0.0001, grad_fn=<SelectBackward>) tensor(0.0009, grad_fn=<SelectBackward>)\n",
      "3.087065186946347e-05 tensor(0.0003, grad_fn=<SelectBackward>) tensor(0.0008, grad_fn=<SelectBackward>)\n",
      "3.0461447522611707e-05 tensor(0.0006, grad_fn=<SelectBackward>) tensor(0.0007, grad_fn=<SelectBackward>)\n",
      "3.5724281133298064e-05 tensor(0.0015, grad_fn=<SelectBackward>) tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "3.354849224024292e-05 tensor(0.0015, grad_fn=<SelectBackward>) tensor(0.0012, grad_fn=<SelectBackward>)\n",
      "3.2625669746266794e-05 tensor(0.0015, grad_fn=<SelectBackward>) tensor(0.0012, grad_fn=<SelectBackward>)\n",
      "3.194850603449595e-05 tensor(0.0015, grad_fn=<SelectBackward>) tensor(0.0011, grad_fn=<SelectBackward>)\n",
      "3.1461769992802147e-05 tensor(0.0015, grad_fn=<SelectBackward>) tensor(0.0010, grad_fn=<SelectBackward>)\n",
      "3.1103262074339e-05 tensor(0.0015, grad_fn=<SelectBackward>) tensor(0.0010, grad_fn=<SelectBackward>)\n",
      "3.072357861810815e-05 tensor(0.0015, grad_fn=<SelectBackward>) tensor(0.0009, grad_fn=<SelectBackward>)\n",
      "3.0359460652107373e-05 tensor(0.0015, grad_fn=<SelectBackward>) tensor(0.0009, grad_fn=<SelectBackward>)\n",
      "3.0356680269960634e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0008, grad_fn=<SelectBackward>)\n",
      "3.012709214544884e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0008, grad_fn=<SelectBackward>)\n",
      "2.983849208249012e-05 tensor(0.0017, grad_fn=<SelectBackward>) tensor(0.0007, grad_fn=<SelectBackward>)\n",
      "2.967410603105236e-05 tensor(0.0018, grad_fn=<SelectBackward>) tensor(0.0007, grad_fn=<SelectBackward>)\n",
      "2.9351169416713674e-05 tensor(0.0020, grad_fn=<SelectBackward>) tensor(0.0006, grad_fn=<SelectBackward>)\n",
      "2.9322796933684003e-05 tensor(0.0021, grad_fn=<SelectBackward>) tensor(0.0006, grad_fn=<SelectBackward>)\n",
      "2.9036831904249993e-05 tensor(0.0023, grad_fn=<SelectBackward>) tensor(0.0006, grad_fn=<SelectBackward>)\n",
      "2.9080152330607234e-05 tensor(0.0025, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "2.8752309788160346e-05 tensor(0.0027, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "2.8653734943873133e-05 tensor(0.0030, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "2.856089128044914e-05 tensor(0.0032, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "2.8258666191049997e-05 tensor(0.0035, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "2.8040394511208433e-05 tensor(0.0038, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "2.979605426389753e-05 tensor(0.0047, grad_fn=<SelectBackward>) tensor(0.0009, grad_fn=<SelectBackward>)\n",
      "2.826399867217333e-05 tensor(0.0046, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "2.792364171000372e-05 tensor(0.0049, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Net_PGEXTRA(torch.nn.Module):\n",
    "    def __init__(self, step_size, num_layers):\n",
    "        super(Net_PGEXTRA, self).__init__()\n",
    "        self.step_size = nn.Parameter(torch.ones(num_layers)*step_size)\n",
    "        self.lam = nn.Parameter(torch.ones(num_layers)*step_size*10)\n",
    "        self.num_layers = num_layers\n",
    "        self.conv=MetropolisConv()\n",
    "    def tgrad_qp(self, A, b, x):\n",
    "        # A: nodes * k * n\n",
    "        # X: nodes * n\n",
    "        # Y: nodes * k\n",
    "        '''grad_A = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            grad_A[i] = A[i].T @ (A[i] @ x[i] - b[i])\n",
    "        return grad_A'''\n",
    "        x_ = torch.unsqueeze(x, axis = -1)\n",
    "        b_ = torch.unsqueeze(b, axis = -1)\n",
    "\n",
    "        A_t = A.transpose(2,3)\n",
    "        grad_A = A_t @ (A @ x_ - b_)\n",
    "        #print(A.shape, x.shape, b.shape)\n",
    "        #print(grad_A.shape)\n",
    "        grad_A = torch.squeeze(grad_A, axis = -1)\n",
    "        #print(grad_A.shape)\n",
    "        return grad_A\n",
    "    \n",
    "    def act(self, x, ii):\n",
    "        tau = self.lam[ii] #* self.step_size[ii]\n",
    "        return F.relu(x - tau) - F.relu( - x - tau)\n",
    "            \n",
    "    def forward(self, W, A, b,pyg_data, max_iter):\n",
    "        (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "        init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "        ret_z = []\n",
    "        \n",
    "        k = 1\n",
    "        x_0 = init_x\n",
    "        x_12 = self.conv(x_0,pyg_data) - self.step_size[0] * self.tgrad_qp(A, b, x_0)\n",
    "        x_1 = self.act(x_12, 0)\n",
    "        \n",
    "        x_hist = [init_x,x_1]\n",
    "        while (k < max_iter):\n",
    "            x_32 = self.conv(x_1,pyg_data) + x_12 - (self.conv(x_0,pyg_data) + x_0)/2 - \\\n",
    "                self.step_size[k] * (self.tgrad_qp(A, b, x_1)-self.tgrad_qp(A, b, x_0))\n",
    "            x_2 = self.act(x_32, k)\n",
    "            \n",
    "            ret_z.append(x_2)\n",
    "\n",
    "            x_0 = x_1\n",
    "            x_1 = x_2\n",
    "            x_12 = x_32\n",
    "\n",
    "            k = k + 1\n",
    "            x_hist.append(x_2)\n",
    "        \n",
    "        ret_z = torch.stack(ret_z)\n",
    "        return ret_z, x_2,x_hist\n",
    "      \n",
    "###main\n",
    "model_PGEXTRA = Net_PGEXTRA(1e-3, num_layers)\n",
    "optimizer = optim.Adam(model_PGEXTRA.parameters(), lr=2e-5)\n",
    "model_PGEXTRA.train()\n",
    "epoch_losses = []\n",
    "for epoch in range(500):\n",
    "    epoch_loss = 0\n",
    "    for iter, (W, A, y, x_true,pyg_data) in enumerate(train_loader):\n",
    "        z, _,_ = model_PGEXTRA(W, A, y, pyg_data,num_layers)\n",
    "        loss = step_loss(0.86,z, x_true)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch_loss, model_PGEXTRA.lam[1], model_PGEXTRA.step_size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN-DGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00047994527812988963 tensor(0.0071, grad_fn=<SelectBackward>) tensor(0.0038, grad_fn=<SelectBackward>)\n",
      "0.00017056674641935388 tensor(0.0099, grad_fn=<SelectBackward>) tensor(0.0056, grad_fn=<SelectBackward>)\n",
      "0.00015947482233968913 tensor(0.0099, grad_fn=<SelectBackward>) tensor(0.0058, grad_fn=<SelectBackward>)\n",
      "0.0001554991899865854 tensor(0.0105, grad_fn=<SelectBackward>) tensor(0.0056, grad_fn=<SelectBackward>)\n",
      "0.00014631832073064288 tensor(0.0105, grad_fn=<SelectBackward>) tensor(0.0059, grad_fn=<SelectBackward>)\n",
      "0.0001648697175369307 tensor(0.0103, grad_fn=<SelectBackward>) tensor(0.0063, grad_fn=<SelectBackward>)\n",
      "0.0001592461680957058 tensor(0.0118, grad_fn=<SelectBackward>) tensor(0.0055, grad_fn=<SelectBackward>)\n",
      "0.00015754647120047593 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0050, grad_fn=<SelectBackward>)\n",
      "0.00013429127989184053 tensor(0.0119, grad_fn=<SelectBackward>) tensor(0.0059, grad_fn=<SelectBackward>)\n",
      "0.00016583654905844014 tensor(0.0132, grad_fn=<SelectBackward>) tensor(0.0053, grad_fn=<SelectBackward>)\n",
      "0.00013677822630597802 tensor(0.0125, grad_fn=<SelectBackward>) tensor(0.0065, grad_fn=<SelectBackward>)\n",
      "0.00012544124365376774 tensor(0.0121, grad_fn=<SelectBackward>) tensor(0.0077, grad_fn=<SelectBackward>)\n",
      "0.00012179180635030207 tensor(0.0117, grad_fn=<SelectBackward>) tensor(0.0087, grad_fn=<SelectBackward>)\n",
      "0.00012389722201078257 tensor(0.0131, grad_fn=<SelectBackward>) tensor(0.0084, grad_fn=<SelectBackward>)\n",
      "0.00012063625717928517 tensor(0.0123, grad_fn=<SelectBackward>) tensor(0.0102, grad_fn=<SelectBackward>)\n",
      "0.00010900885354203638 tensor(0.0120, grad_fn=<SelectBackward>) tensor(0.0118, grad_fn=<SelectBackward>)\n",
      "0.00010504787383069925 tensor(0.0117, grad_fn=<SelectBackward>) tensor(0.0137, grad_fn=<SelectBackward>)\n",
      "9.558323199598817e-05 tensor(0.0117, grad_fn=<SelectBackward>) tensor(0.0155, grad_fn=<SelectBackward>)\n",
      "8.307600751322752e-05 tensor(0.0119, grad_fn=<SelectBackward>) tensor(0.0173, grad_fn=<SelectBackward>)\n",
      "7.437278384259116e-05 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0192, grad_fn=<SelectBackward>)\n",
      "6.91656016442721e-05 tensor(0.0130, grad_fn=<SelectBackward>) tensor(0.0210, grad_fn=<SelectBackward>)\n",
      "6.410528396827431e-05 tensor(0.0140, grad_fn=<SelectBackward>) tensor(0.0229, grad_fn=<SelectBackward>)\n",
      "7.342621506722935e-05 tensor(0.0164, grad_fn=<SelectBackward>) tensor(0.0246, grad_fn=<SelectBackward>)\n",
      "6.336972955978126e-05 tensor(0.0155, grad_fn=<SelectBackward>) tensor(0.0268, grad_fn=<SelectBackward>)\n",
      "5.720919443774619e-05 tensor(0.0169, grad_fn=<SelectBackward>) tensor(0.0285, grad_fn=<SelectBackward>)\n",
      "7.058821347527555e-05 tensor(0.0155, grad_fn=<SelectBackward>) tensor(0.0323, grad_fn=<SelectBackward>)\n",
      "6.20683592842397e-05 tensor(0.0165, grad_fn=<SelectBackward>) tensor(0.0317, grad_fn=<SelectBackward>)\n",
      "5.7903024639927025e-05 tensor(0.0170, grad_fn=<SelectBackward>) tensor(0.0319, grad_fn=<SelectBackward>)\n",
      "5.5245686439775454e-05 tensor(0.0173, grad_fn=<SelectBackward>) tensor(0.0326, grad_fn=<SelectBackward>)\n",
      "5.3081305168234394e-05 tensor(0.0178, grad_fn=<SelectBackward>) tensor(0.0336, grad_fn=<SelectBackward>)\n",
      "5.103950536522461e-05 tensor(0.0185, grad_fn=<SelectBackward>) tensor(0.0349, grad_fn=<SelectBackward>)\n",
      "4.96922757520224e-05 tensor(0.0196, grad_fn=<SelectBackward>) tensor(0.0362, grad_fn=<SelectBackward>)\n",
      "4.812106010376738e-05 tensor(0.0212, grad_fn=<SelectBackward>) tensor(0.0375, grad_fn=<SelectBackward>)\n",
      "4.724225721020048e-05 tensor(0.0232, grad_fn=<SelectBackward>) tensor(0.0388, grad_fn=<SelectBackward>)\n",
      "4.61188341205343e-05 tensor(0.0258, grad_fn=<SelectBackward>) tensor(0.0401, grad_fn=<SelectBackward>)\n",
      "4.558678813282313e-05 tensor(0.0288, grad_fn=<SelectBackward>) tensor(0.0414, grad_fn=<SelectBackward>)\n",
      "4.419260767463129e-05 tensor(0.0325, grad_fn=<SelectBackward>) tensor(0.0427, grad_fn=<SelectBackward>)\n",
      "4.6391918772314966e-05 tensor(0.0388, grad_fn=<SelectBackward>) tensor(0.0416, grad_fn=<SelectBackward>)\n",
      "7.726550859388226e-05 tensor(0.0456, grad_fn=<SelectBackward>) tensor(0.0347, grad_fn=<SelectBackward>)\n",
      "7.344460732383595e-05 tensor(0.0457, grad_fn=<SelectBackward>) tensor(0.0346, grad_fn=<SelectBackward>)\n",
      "7.102695440153184e-05 tensor(0.0457, grad_fn=<SelectBackward>) tensor(0.0345, grad_fn=<SelectBackward>)\n",
      "7.002898962582549e-05 tensor(0.0458, grad_fn=<SelectBackward>) tensor(0.0345, grad_fn=<SelectBackward>)\n",
      "6.93225110808271e-05 tensor(0.0459, grad_fn=<SelectBackward>) tensor(0.0344, grad_fn=<SelectBackward>)\n",
      "6.746892393039161e-05 tensor(0.0460, grad_fn=<SelectBackward>) tensor(0.0343, grad_fn=<SelectBackward>)\n",
      "6.701109805362648e-05 tensor(0.0462, grad_fn=<SelectBackward>) tensor(0.0342, grad_fn=<SelectBackward>)\n",
      "6.566255160578294e-05 tensor(0.0463, grad_fn=<SelectBackward>) tensor(0.0341, grad_fn=<SelectBackward>)\n",
      "6.490408395620761e-05 tensor(0.0464, grad_fn=<SelectBackward>) tensor(0.0340, grad_fn=<SelectBackward>)\n",
      "6.386023142113118e-05 tensor(0.0466, grad_fn=<SelectBackward>) tensor(0.0339, grad_fn=<SelectBackward>)\n",
      "6.251969011827896e-05 tensor(0.0468, grad_fn=<SelectBackward>) tensor(0.0338, grad_fn=<SelectBackward>)\n",
      "6.132977603101608e-05 tensor(0.0470, grad_fn=<SelectBackward>) tensor(0.0337, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Net_DGD(torch.nn.Module):\n",
    "    def __init__(self, step_size, num_layers):\n",
    "        super(Net_DGD, self).__init__()\n",
    "        self.step_size = nn.Parameter(torch.ones(num_layers)*step_size)\n",
    "        self.lam = nn.Parameter(torch.ones(num_layers)*step_size*10)\n",
    "        self.num_layers = num_layers\n",
    "        self.conv=MetropolisConv()\n",
    "    def tgrad_qp(self, A, b, x):\n",
    "        # A: nodes * k * n\n",
    "        # X: nodes * n\n",
    "        # Y: nodes * k\n",
    "        '''grad_A = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            grad_A[i] = A[i].T @ (A[i] @ x[i] - b[i])\n",
    "        return grad_A'''\n",
    "        x_ = torch.unsqueeze(x, axis = -1)\n",
    "        b_ = torch.unsqueeze(b, axis = -1)\n",
    "\n",
    "        A_t = A.transpose(2,3)\n",
    "        grad_A = A_t @ (A @ x_ - b_)\n",
    "        #print(A.shape, x.shape, b.shape)\n",
    "        #print(grad_A.shape)\n",
    "        grad_A = torch.squeeze(grad_A, axis = -1)\n",
    "        #print(grad_A.shape)\n",
    "        return grad_A\n",
    "    \n",
    "    def act(self, x, ii):\n",
    "        tau = self.lam[ii] #* self.step_size[ii]\n",
    "        return F.relu(x - tau) - F.relu( - x - tau)\n",
    "            \n",
    "    def forward(self, W, A, b,pyg_data, max_iter):\n",
    "        (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "        init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "        ret_z = []\n",
    "        \n",
    "        k = 1\n",
    "        x_0 = init_x\n",
    "        x_12 = self.conv(x_0,pyg_data) - self.step_size[0] * self.tgrad_qp(A, b, x_0)\n",
    "        x_1 = self.act(x_12, 0)\n",
    "        \n",
    "        x_hist = [init_x,x_1]\n",
    "        while (k < max_iter):\n",
    "            #x_32 = self.conv(x_1,pyg_data) + x_12 - (self.conv(x_0,pyg_data) + x_0)/2 - \\\n",
    "            #    self.step_size[k] * (self.tgrad_qp(A, b, x_1)-self.tgrad_qp(A, b, x_0))\n",
    "            x_32 = self.conv(x_1,pyg_data) - self.step_size[k] * self.tgrad_qp(A, b, x_1)\n",
    "            x_2 = self.act(x_32, k)\n",
    "            \n",
    "            ret_z.append(x_2)\n",
    "\n",
    "            x_0 = x_1\n",
    "            x_1 = x_2\n",
    "            x_12 = x_32\n",
    "\n",
    "            k = k + 1\n",
    "            x_hist.append(x_2)\n",
    "        \n",
    "        ret_z = torch.stack(ret_z)\n",
    "        return ret_z, x_2,x_hist\n",
    "def step_loss(gamma,x, y):\n",
    "    #gamma = 0.75\n",
    "    n_steps = x.shape[0]\n",
    "    #print(n_steps)\n",
    "    #di = torch.ones((n_steps)) * gamma\n",
    "    power = torch.tensor(range(n_steps, 0, -1))\n",
    "    gamma_a = 1/ power\n",
    "    gamma_a = gamma_a.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    y = torch.unsqueeze(y, axis = 0)\n",
    "    ele_loss = gamma_a * (x - y) **2\n",
    "    #print(ele_loss.shape)\n",
    "    #print(torch.mean(ele_loss,  (1,2,3) ))\n",
    "    loss = torch.mean(ele_loss)\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "model_DGD = Net_DGD(1e-3, num_layers)\n",
    "optimizer = optim.Adam(model_DGD.parameters(), lr=1e-4)\n",
    "model_DGD.train()\n",
    "epoch_losses = []\n",
    "for epoch in range(500):\n",
    "    epoch_loss = 0\n",
    "    for iter, (W, A, y, x_true,pyg_data) in enumerate(train_loader):\n",
    "        z, _,_ = model_DGD(W, A, y, pyg_data,num_layers)\n",
    "        loss = step_loss(0.8965,z, x_true)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch_loss, model_DGD.lam[1], model_DGD.step_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Net_NIDS(torch.nn.Module):\\n    def __init__(self, step_size, num_layers, num_nodes):\\n        super(Net_NIDS, self).__init__()\\n        self.step_size = nn.Parameter(torch.ones(num_layers,num_nodes)*step_size)\\n        self.lam = nn.Parameter(torch.ones(num_layers,num_nodes)*step_size*10)\\n        self.c = nn.Parameter(torch.ones(num_layers)*step_size)\\n        self.num_layers = num_layers\\n        self.conv=MetropolisConv()\\n        \\n    def tgrad_qp(self, A, b, x):\\n        # A: nodes * k * n\\n        # X: nodes * n\\n        # Y: nodes * k\\n\\n        x_ = torch.unsqueeze(x, axis = -1)\\n        b_ = torch.unsqueeze(b, axis = -1)\\n\\n        A_t = A.transpose(2,3)\\n        grad_A = A_t @ (A @ x_ - b_)\\n        grad_A = torch.squeeze(grad_A, axis = -1)\\n        return grad_A\\n    \\n    def act(self, x, ii):\\n        tau = (self.lam[ii]).unsqueeze(0).unsqueeze(-1) #* self.step_size[ii]\\n        return F.relu(x - tau) - F.relu( - x - tau)\\n            \\n    def forward(self, W, A, b,pyg_data, max_iter):\\n        (batch_size, num_of_nodes, _, dim) = A.shape\\n        init_x = torch.zeros((batch_size, num_of_nodes, dim))\\n        ret_z = []\\n        \\n        k = 1\\n        x_0 = init_x\\n        x_12 = x_0 - torch.diag(self.step_size[0]).unsqueeze(0)@ self.tgrad_qp(A, b, x_0)\\n        x_1 = self.act(x_12, 0)\\n        \\n        x_hist = [init_x,x_1]\\n        \\n        while (k < max_iter):\\n            c = self.c[k]/(2*torch.max(self.step_size[k]))\\n            #W_hat = torch.eye(num_of_nodes).unsqueeze(0)- c*torch.diag(self.step_size[k]).unsqueeze(0)@(torch.eye(num_of_nodes).unsqueeze(0)- W)\\n            #print(W_hat)\\n            temp = 2*x_1-x_0 - torch.diag(self.step_size[k])@(self.tgrad_qp(A, b, x_1)-self.tgrad_qp(A, b, x_0))\\n            conv_result = self.conv(temp,pyg_data)\\n            x_32 = x_12 - x_1 + temp - c*torch.diag(self.step_size[k]).unsqueeze(0)@ (temp - conv_result)\\n            #x_32 = x_12-x_1 + self.conv(temp,pyg_data)\\n            #x_32 =x_12 - x_1 + w@temp\\n            x_2 = self.act(x_32, k)\\n            \\n            ret_z.append(x_2)\\n\\n            x_0 = x_1\\n            x_1 = x_2\\n            x_12 = x_32\\n            \\n\\n            k = k + 1\\n            x_hist.append(x_2)\\n        \\n        ret_z = torch.stack(ret_z)\\n        return ret_z, x_2,x_hist\\nmodel_NIDS = Net_NIDS(1e-3, num_layers,num_nodes)\\noptimizer = optim.Adam(model_NIDS.parameters(), lr=1e-4)\\nmodel_NIDS.train()\\nepoch_losses = []\\nfor epoch in range(500):\\n    epoch_loss = 0\\n    for iter, (W, A, y, x_true,pyg_data) in enumerate(train_loader):\\n        z, _,_ = model_NIDS(W, A, y, pyg_data,num_layers)\\n        loss = step_loss(0.83,z, x_true)\\n        \\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n        epoch_loss += loss.detach().item()\\n    epoch_loss /= (iter + 1)\\n    if(epoch % 10 == 0):\\n        print(epoch_loss, model_NIDS.lam[1], model_NIDS.step_size[1])\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Net_NIDS(torch.nn.Module):\n",
    "    def __init__(self, step_size, num_layers, num_nodes):\n",
    "        super(Net_NIDS, self).__init__()\n",
    "        self.step_size = nn.Parameter(torch.ones(num_layers,num_nodes)*step_size)\n",
    "        self.lam = nn.Parameter(torch.ones(num_layers,num_nodes)*step_size*10)\n",
    "        self.c = nn.Parameter(torch.ones(num_layers)*step_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.conv=MetropolisConv()\n",
    "        \n",
    "    def tgrad_qp(self, A, b, x):\n",
    "        # A: nodes * k * n\n",
    "        # X: nodes * n\n",
    "        # Y: nodes * k\n",
    "\n",
    "        x_ = torch.unsqueeze(x, axis = -1)\n",
    "        b_ = torch.unsqueeze(b, axis = -1)\n",
    "\n",
    "        A_t = A.transpose(2,3)\n",
    "        grad_A = A_t @ (A @ x_ - b_)\n",
    "        grad_A = torch.squeeze(grad_A, axis = -1)\n",
    "        return grad_A\n",
    "    \n",
    "    def act(self, x, ii):\n",
    "        tau = (self.lam[ii]).unsqueeze(0).unsqueeze(-1) #* self.step_size[ii]\n",
    "        return F.relu(x - tau) - F.relu( - x - tau)\n",
    "            \n",
    "    def forward(self, W, A, b,pyg_data, max_iter):\n",
    "        (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "        init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "        ret_z = []\n",
    "        \n",
    "        k = 1\n",
    "        x_0 = init_x\n",
    "        x_12 = x_0 - torch.diag(self.step_size[0]).unsqueeze(0)@ self.tgrad_qp(A, b, x_0)\n",
    "        x_1 = self.act(x_12, 0)\n",
    "        \n",
    "        x_hist = [init_x,x_1]\n",
    "        \n",
    "        while (k < max_iter):\n",
    "            c = self.c[k]/(2*torch.max(self.step_size[k]))\n",
    "            #W_hat = torch.eye(num_of_nodes).unsqueeze(0)- c*torch.diag(self.step_size[k]).unsqueeze(0)@(torch.eye(num_of_nodes).unsqueeze(0)- W)\n",
    "            #print(W_hat)\n",
    "            temp = 2*x_1-x_0 - torch.diag(self.step_size[k])@(self.tgrad_qp(A, b, x_1)-self.tgrad_qp(A, b, x_0))\n",
    "            conv_result = self.conv(temp,pyg_data)\n",
    "            x_32 = x_12 - x_1 + temp - c*torch.diag(self.step_size[k]).unsqueeze(0)@ (temp - conv_result)\n",
    "            #x_32 = x_12-x_1 + self.conv(temp,pyg_data)\n",
    "            #x_32 =x_12 - x_1 + w@temp\n",
    "            x_2 = self.act(x_32, k)\n",
    "            \n",
    "            ret_z.append(x_2)\n",
    "\n",
    "            x_0 = x_1\n",
    "            x_1 = x_2\n",
    "            x_12 = x_32\n",
    "            \n",
    "\n",
    "            k = k + 1\n",
    "            x_hist.append(x_2)\n",
    "        \n",
    "        ret_z = torch.stack(ret_z)\n",
    "        return ret_z, x_2,x_hist\n",
    "model_NIDS = Net_NIDS(1e-3, num_layers,num_nodes)\n",
    "optimizer = optim.Adam(model_NIDS.parameters(), lr=1e-4)\n",
    "model_NIDS.train()\n",
    "epoch_losses = []\n",
    "for epoch in range(500):\n",
    "    epoch_loss = 0\n",
    "    for iter, (W, A, y, x_true,pyg_data) in enumerate(train_loader):\n",
    "        z, _,_ = model_NIDS(W, A, y, pyg_data,num_layers)\n",
    "        loss = step_loss(0.83,z, x_true)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch_loss, model_NIDS.lam[1], model_NIDS.step_size[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Origin Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tgrad_qp(A, b, x):\n",
    "    # A: nodes * k * n\n",
    "    # X: nodes * n\n",
    "    # Y: nodes * k\n",
    "    '''grad_A = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        grad_A[i] = A[i].T @ (A[i] @ x[i] - b[i])\n",
    "    return grad_A'''\n",
    "    x_ = torch.unsqueeze(x, axis = -1)\n",
    "    b_ = torch.unsqueeze(b, axis = -1)\n",
    "    \n",
    "    A_t = A.transpose(2,3)\n",
    "    grad_A = A_t @ (A @ x_ - b_)\n",
    "    # print(A.shape, x.shape, b.shape)\n",
    "    grad_A = torch.squeeze(grad_A, axis = -1)\n",
    "    return grad_A\n",
    "\n",
    "def torch_soft(x, tau):\n",
    "    return F.relu(x - tau) - F.relu( - x - tau)\n",
    "\n",
    "def opt_distance(x,opt):\n",
    "    error = 0\n",
    "    batch_size = x.shape[0]\n",
    "    num_of_nodes = x.shape[1]\n",
    "    error = np.linalg.norm(x-opt)**2\n",
    "    return error/num_of_nodes/batch_size\n",
    "\n",
    "def hist_nmse(x_hist,opt):\n",
    "    error = []\n",
    "    iteration = len(x_hist)\n",
    "    #print(iteration)\n",
    "    for k in range(iteration):\n",
    "        error.append(10*np.log10(opt_distance(x_hist[k].detach(),opt)))\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin PG-EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.01 \t 0.5940539376917586 \t 0.4680586206153548\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.05 \t 0.5926524396339736 \t 0.46249895539447794\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.1 \t 0.5910356479359616 \t 0.4559274614364422\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.3 \t 0.5860771867587463 \t 0.43408721601314215\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.5 \t 0.5833889446061293 \t 0.41894614409603675\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.7 \t 0.5826519235668893 \t 0.409104285640251\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 1 \t 0.5847374461508589 \t 0.4023254521409562\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 5 \t 0.7703447354999371 \t 0.6478505945503712\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.01 \t 0.5301225537094361 \t 0.415722756291223\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.05 \t 0.5271336443722248 \t 0.40687496252940764\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.1 \t 0.5236207424564127 \t 0.3964408589277609\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.3 \t 0.5121031546092781 \t 0.362220444584389\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.5 \t 0.5043861842132464 \t 0.3389734285821923\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.7 \t 0.4998694674018843 \t 0.32396787785369086\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 1 \t 0.4981388679557294 \t 0.3129880424962921\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 5 \t 0.7123190027009987 \t 0.5892479285714289\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.01 \t 0.467728493232471 \t 0.36742037890078977\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.05 \t 0.46227280331077053 \t 0.35378411973245233\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.1 \t 0.4558335846525024 \t 0.33788173565810026\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.3 \t 0.434376467559503 \t 0.28774974921022656\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.5 \t 0.4194138549759536 \t 0.25594673657615385\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.7 \t 0.409673255263624 \t 0.23674523565794697\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 1 \t 0.402953309749153 \t 0.22396583507565265\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 5 \t 0.6474087957968295 \t 0.5366686070618453\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.01 \t 0.3672762931329199 \t 0.2923963505486318\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.05 \t 0.353846933402383 \t 0.26362702612325667\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.1 \t 0.3382127295366972 \t 0.23203015178851094\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.3 \t 0.2887298166279379 \t 0.14891818573349336\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.5 \t 0.25700397423775756 \t 0.110967441131525\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.7 \t 0.23772714761985297 \t 0.09564610865531904\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 1 \t 0.22477849013358356 \t 0.09352968252077015\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 5 \t 0.5361935517881357 \t 0.47802591522297194\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.01 \t 0.27282552199581006 \t 0.22073285715960084\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.05 \t 0.2374765949004377 \t 0.15390678756125273\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.1 \t 0.19999572756187992 \t 0.09615506519395467\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.3 \t 0.10989206281882115 \t 0.021763587058577397\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.5 \t 0.07582068177598968 \t 0.01747684283052979\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.7 \t 0.06552564392336535 \t 0.023949552897089346\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 1 \t 0.06924297520704567 \t 0.04051940864338803\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 5 \t 0.4703033346608281 \t 0.4641906695382659\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.01 \t 14208.244755363941 \t 37738906243424.77\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.05 \t 11421.726110506057 \t 30324862304317.95\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.1 \t 8445.307487022877 \t 22408387417636.992\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.3 \t 1359.277442410655 \t 3575826630616.352\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.5 \t 0.6139738164287992 \t 524392965.253125\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.7 \t 0.03626997108796968 \t 0.020719137638574924\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 1 \t 0.048247790596779395 \t 0.0385439632045568\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 5 \t 0.4654260416605466 \t 0.4640057638791204\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.01 \t 6.256789565471774e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.05 \t 5.7769127150182714e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.1 \t 5.207994164633043e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.3 \t 3.2544923208190645e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.5 \t 1.8616474045125856e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.7 \t 9.28688575396868e+22 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 1 \t 1.9539885469502116e+22 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 5 \t 0.46416835338743295 \t 0.46398926246183875\n"
     ]
    }
   ],
   "source": [
    "def torch_PGEXTRA(W, A, b, max_iter, step_size,tau):\n",
    "    (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "    init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "    \n",
    "    \n",
    "    (batch_size, num_of_nodes, dim) = init_x.shape\n",
    "    I = torch.unsqueeze(torch.eye(num_of_nodes), axis = 0)\n",
    "    I = I.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    W_hat = (W + I)/2\n",
    "    \n",
    "    #initialization\n",
    "    k = 1\n",
    "    x_0 = init_x\n",
    "    x_12 = W @ x_0 - step_size * tgrad_qp(A, b, x_0)\n",
    "    x_1 = torch_soft(x_12, tau*step_size)\n",
    "    \n",
    "    x_hist = [init_x,x_1] #add for plot\n",
    "    while (k < max_iter):\n",
    "        \n",
    "        x_32 = W@x_1 + x_12 - W_hat@x_0 - \\\n",
    "            step_size*(tgrad_qp(A, b, x_1)-tgrad_qp(A, b, x_0))\n",
    "        x_2 = torch_soft(x_32, tau*step_size)\n",
    "        \n",
    "        x_0 = x_1\n",
    "        x_1 = x_2\n",
    "        x_12 = x_32\n",
    "        \n",
    "        k = k + 1\n",
    "        \n",
    "        x_hist.append(x_2)\n",
    "        \n",
    "    return x_2,x_hist\n",
    "\n",
    "lams = [5e-4,7e-4,1e-3, 2e-3,5e-3,7e-3,1e-2]\n",
    "taus = [1e-2, 5e-2,1e-1,3e-1,5e-1, 7e-1,1, 5]\n",
    "best_error = 100\n",
    "best_par = {}\n",
    "for lam in lams:\n",
    "    for tau in taus:\n",
    "        for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "            original,origin_hist = torch_PGEXTRA(W, A, y, 100, lam, tau)\n",
    "            loss2 = opt_distance(original.detach().numpy(), x_true.numpy())\n",
    "            loss1 = opt_distance(origin_hist[num_layers].detach().numpy(),x_true.numpy())\n",
    "            \n",
    "            print(\"lamb\\ttau\\tlayer_loss\\t\\tfinal_loss\")\n",
    "            print(lam,'\\t', tau, '\\t',loss1,'\\t',loss2)\n",
    "            \n",
    "            if loss2 < best_error:\n",
    "                best_par['lam'] = lam\n",
    "                best_par['tau'] = tau\n",
    "                best_error = loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lam': 0.005, 'tau': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(best_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin DGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.01 \t 0.605324313603116 \t 0.4777560819402879\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.05 \t 0.6041230399185151 \t 0.47247883532072776\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.1 \t 0.6027498381328769 \t 0.46627429917640983\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.3 \t 0.5986390795216721 \t 0.44572820769326243\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.5 \t 0.5966072908644564 \t 0.43150386412894476\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.7 \t 0.596412417690044 \t 0.42242122252012637\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 1 \t 0.5991846072476182 \t 0.4166333064153605\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 5 \t 0.7770043687039943 \t 0.6565058805164881\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.01 \t 0.5449529025194424 \t 0.4275345266469249\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.05 \t 0.5422909490196325 \t 0.4190731938183035\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.1 \t 0.5391815688926727 \t 0.40915404446773934\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.3 \t 0.5290939575211379 \t 0.37675980513660945\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.5 \t 0.522510301244918 \t 0.3547385442897958\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.7 \t 0.5189351923247159 \t 0.34069950236557817\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 1 \t 0.518407741313924 \t 0.3309626039515733\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 5 \t 0.7228559435361603 \t 0.6009312514247794\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.01 \t 0.4865721544785647 \t 0.3816777560041828\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.05 \t 0.4816078651778589 \t 0.3685525916798797\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.1 \t 0.47578300551690517 \t 0.3533543154448562\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.3 \t 0.4565946680083307 \t 0.3056183052720899\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.5 \t 0.4433946277025389 \t 0.2752672229898162\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.7 \t 0.4351414300562173 \t 0.2571117036353753\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 1 \t 0.4302776880126403 \t 0.24558072956048999\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 5 \t 0.6631267220888113 \t 0.5515168847821478\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.01 \t 0.3947319084811916 \t 0.31191243160062004\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.05 \t 0.38217612475382523 \t 0.2840330423829146\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.1 \t 0.3676902214882303 \t 0.2535609069976799\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.3 \t 0.3223552369956906 \t 0.1732036889072333\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.5 \t 0.29358641629327215 \t 0.13569167154634487\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.7 \t 0.27655102460332454 \t 0.12016410144421069\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 1 \t 0.26609735030499176 \t 0.11802508074586694\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 5 \t 0.5628771209345431 \t 0.4987725284595236\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.01 \t 0.31318057835273977 \t 0.2501581664487021\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.05 \t 0.2794851188737739 \t 0.18322170445469235\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.1 \t 0.2439440283472941 \t 0.12510365435410903\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.3 \t 0.15809911026171902 \t 0.042975259893690235\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.5 \t 0.12358578601858607 \t 0.03417662114119639\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.7 \t 0.11223631116009347 \t 0.04056274076405361\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 1 \t 0.11575338206776405 \t 0.059824248059213006\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 5 \t 0.5098841484872465 \t 0.4999362906619281\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.01 \t 68052561144.05 \t 9.76931508131167e+26\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.05 \t 59891850020.738 \t 8.572871616527305e+26\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.1 \t 50558933362.322 \t 7.206389563987081e+26\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.3 \t 22287054995.920128 \t 3.087647371844305e+26\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.5 \t 7079786285.390281 \t 9.099169397754408e+25\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 0.7 \t 1234012448.6381328 \t 1.2053789406689961e+25\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 1 \t 31545888.509980593 \t 9.147792721736306e+21\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.007 \t 5 \t 0.511862741134044 \t 0.5086370710864303\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.01 \t 9.796332749813211e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.05 \t 9.15170750349963e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.1 \t 8.37999855174287e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.3 \t 5.6723953445580546e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.5 \t 3.62664438639385e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.7 \t 2.118144026984666e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 1 \t 7.187142605995812e+25 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 5 \t 0.5205962064808773 \t 0.51992274850377\n"
     ]
    }
   ],
   "source": [
    "def torch_DGD(W, A, b, max_iter, step_size,tau):\n",
    "    (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "    init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "    \n",
    "    \n",
    "    (batch_size, num_of_nodes, dim) = init_x.shape\n",
    "    I = torch.unsqueeze(torch.eye(num_of_nodes), axis = 0)\n",
    "    I = I.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    W_hat = (W + I)/2\n",
    "    \n",
    "    #initialization\n",
    "    k = 1\n",
    "    x_0 = init_x\n",
    "    x_12 = W @ x_0 - step_size * tgrad_qp(A, b, x_0)\n",
    "    x_1 = torch_soft(x_12, tau*step_size)\n",
    "    \n",
    "    x_hist = [init_x,x_1] #add for plot\n",
    "    while (k < max_iter):\n",
    "        \n",
    "        x_32 = W@x_1 -  step_size*tgrad_qp(A, b, x_1)\n",
    "        x_2 = torch_soft(x_32, tau * step_size)\n",
    "        \n",
    "        x_0 = x_1\n",
    "        x_1 = x_2\n",
    "        x_12 = x_32\n",
    "        \n",
    "        k = k + 1\n",
    "        \n",
    "        x_hist.append(x_2)\n",
    "        \n",
    "    return x_2,x_hist\n",
    "lams = [5e-4,7e-4,1e-3, 2e-3,5e-3,7e-3,1e-2]\n",
    "taus = [1e-2, 5e-2,1e-1,3e-1,5e-1, 7e-1,1, 5]\n",
    "best_error = 100\n",
    "best_par = {}\n",
    "for lam in lams:\n",
    "    for tau in taus:\n",
    "        for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "            original,origin_hist = torch_DGD(W, A, y, 100, lam, tau)\n",
    "            loss2 = opt_distance(original.detach().numpy(), x_true.numpy())\n",
    "            loss1 = opt_distance(origin_hist[num_layers].detach().numpy(),x_true.numpy())\n",
    "            \n",
    "            print(\"lamb\\ttau\\tlayer_loss\\t\\tfinal_loss\")\n",
    "            print(lam,'\\t', tau, '\\t',loss1,'\\t',loss2)\n",
    "            if loss2 < best_error:\n",
    "                best_par['lam'] = lam\n",
    "                best_par['tau'] = tau\n",
    "                best_error = loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lam': 0.005, 'tau': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(best_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin NIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef torch_NIDS(W, A, b, max_iter, step_size,tau):\\n    (batch_size, num_of_nodes, _, dim) = A.shape\\n    init_x = torch.zeros((batch_size, num_of_nodes, dim))\\n    c = 1/(2*step_size)\\n    \\n    (batch_size, num_of_nodes, dim) = init_x.shape\\n    I = torch.unsqueeze(torch.eye(num_of_nodes), axis = 0)\\n    I = I.repeat(batch_size, 1, 1)\\n    \\n    \\n    #initialization\\n    k = 1\\n    x_0 = init_x\\n    #print(alpha.unsqueeze(-1).shape)\\n    x_12 = x_0 -step_size* tgrad_qp(A, b, x_0)\\n    x_1 = torch_soft(x_12, tau*step_size)\\n    \\n    x_hist = [init_x,x_1] #add for plot\\n    while (k < max_iter):\\n        W_hat = torch.eye(num_of_nodes).unsqueeze(0)- c*step_size*(torch.eye(num_of_nodes).unsqueeze(0)- W)\\n        x_32 = x_12-x_1 + W_hat@(2*x_1-x_0 - step_size*(tgrad_qp(A, b, x_1)-tgrad_qp(A, b, x_0)))\\n        x_2 = torch_soft(x_32, tau*step_size)\\n        \\n        x_0 = x_1\\n        x_1 = x_2\\n        x_12 = x_32\\n        \\n        k = k + 1\\n        \\n        x_hist.append(x_2)\\n        \\n    return x_2,x_hist\\nlams = [5e-4,1e-3, 5e-3,1e-2]\\ntaus = [1e-2, 5e-1, 1, 5]\\nbest_error = 100\\nbest_par = {}\\n#cs = [ 5e-1, 1,10,20,50,200]\\nfor lam in lams:\\n    for tau in taus:\\n        for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\\n            original,origin_hist = torch_NIDS(W, A, y, 100, lam, tau)\\n            loss2 = opt_distance(original.detach().numpy(), x_true.numpy())\\n            loss1 = opt_distance(origin_hist[num_layers].detach().numpy(),x_true.numpy())\\n            \\n            print(\"lamb\\t tau\\t c\\t layer_loss\\t\\t final_loss\")\\n            print(lam,\\'\\t\\', tau, \\'\\t\\',1/(2*lam),\\'\\t\\',loss1,\\'\\t\\',loss2)\\n            if loss2 < best_error:\\n                best_par[\\'lam\\'] = lam\\n                best_par[\\'tau\\'] = tau\\n                best_par[\\'c\\'] = 1/(2*lam)\\n                best_error = loss2\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def torch_NIDS(W, A, b, max_iter, step_size,tau):\n",
    "    (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "    init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "    c = 1/(2*step_size)\n",
    "    \n",
    "    (batch_size, num_of_nodes, dim) = init_x.shape\n",
    "    I = torch.unsqueeze(torch.eye(num_of_nodes), axis = 0)\n",
    "    I = I.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    \n",
    "    #initialization\n",
    "    k = 1\n",
    "    x_0 = init_x\n",
    "    #print(alpha.unsqueeze(-1).shape)\n",
    "    x_12 = x_0 -step_size* tgrad_qp(A, b, x_0)\n",
    "    x_1 = torch_soft(x_12, tau*step_size)\n",
    "    \n",
    "    x_hist = [init_x,x_1] #add for plot\n",
    "    while (k < max_iter):\n",
    "        W_hat = torch.eye(num_of_nodes).unsqueeze(0)- c*step_size*(torch.eye(num_of_nodes).unsqueeze(0)- W)\n",
    "        x_32 = x_12-x_1 + W_hat@(2*x_1-x_0 - step_size*(tgrad_qp(A, b, x_1)-tgrad_qp(A, b, x_0)))\n",
    "        x_2 = torch_soft(x_32, tau*step_size)\n",
    "        \n",
    "        x_0 = x_1\n",
    "        x_1 = x_2\n",
    "        x_12 = x_32\n",
    "        \n",
    "        k = k + 1\n",
    "        \n",
    "        x_hist.append(x_2)\n",
    "        \n",
    "    return x_2,x_hist\n",
    "lams = [5e-4,1e-3, 5e-3,1e-2]\n",
    "taus = [1e-2, 5e-1, 1, 5]\n",
    "best_error = 100\n",
    "best_par = {}\n",
    "#cs = [ 5e-1, 1,10,20,50,200]\n",
    "for lam in lams:\n",
    "    for tau in taus:\n",
    "        for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "            original,origin_hist = torch_NIDS(W, A, y, 100, lam, tau)\n",
    "            loss2 = opt_distance(original.detach().numpy(), x_true.numpy())\n",
    "            loss1 = opt_distance(origin_hist[num_layers].detach().numpy(),x_true.numpy())\n",
    "            \n",
    "            print(\"lamb\\t tau\\t c\\t layer_loss\\t\\t final_loss\")\n",
    "            print(lam,'\\t', tau, '\\t',1/(2*lam),'\\t',loss1,'\\t',loss2)\n",
    "            if loss2 < best_error:\n",
    "                best_par['lam'] = lam\n",
    "                best_par['tau'] = tau\n",
    "                best_par['c'] = 1/(2*lam)\n",
    "                best_error = loss2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lam': 0.005, 'tau': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(best_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "    _,pred_PGEXTRA,pred_PGEXTRA_hist = model_PGEXTRA(W, A, y, pyg_data,num_layers)\n",
    "    _,pred_DGD,pred_DGD_hist = model_DGD(W, A, y, pyg_data,num_layers)\n",
    "    #_,pred_NIDS,pred_NIDS_hist = model_NIDS(W, A, y, pyg_data,num_layers)\n",
    "    \n",
    "    original_PGEXTRA,original_PGEXTRA_hist = torch_PGEXTRA(W, A, y, 500,0.005,0.5)\n",
    "    original_DGD, original_DGD_hist = torch_DGD(W, A, y, 500,0.005,0.5)\n",
    "    #original_NIDS, original_NIDS_hist = torch_NIDS(W, A, y, 200,0.005,0.01)\n",
    "\n",
    "\n",
    "origin_PGEXTRA_error = hist_nmse(original_PGEXTRA_hist,x_true)\n",
    "origin_DGD_error = hist_nmse(original_DGD_hist,x_true)\n",
    "#origin_NIDS_error = hist_nmse(original_NIDS_hist,x_true)\n",
    "pred_PGEXTRA_error = hist_nmse(pred_PGEXTRA_hist,x_true)\n",
    "pred_DGD_error = hist_nmse(pred_DGD_hist,x_true)\n",
    "#pred_NIDS_error = hist_nmse(pred_NIDS_hist,x_true)\n",
    "\n",
    "long_end = 200\n",
    "x_long = [i for i in range(long_end+1)]\n",
    "plt.plot(x_long,origin_DGD_error[:long_end+1],linewidth=2,linestyle='--',color = 'tab:red')\n",
    "plt.plot(x_long,origin_PGEXTRA_error[:long_end+1],linewidth=2,linestyle='--',color = 'tab:blue' )\n",
    "#plt.plot(x_long,origin_NIDS_error[:long_end+1],linewidth=3)\n",
    "\n",
    "x = [i for i in range(num_layers+1)]\n",
    "plt.plot(x,pred_DGD_error[:num_layers+1],linewidth=2,color = 'tab:red')\n",
    "plt.plot(x,pred_PGEXTRA_error[:num_layers+1],linewidth=2,color = 'tab:blue')\n",
    "#plt.plot(x,pred_NIDS_error[:num_layers+1],linewidth=3)\n",
    "\n",
    "plt.legend(['Prox-DGD','PG-EXTRA','GNN-Prox-DGD','GNN-PG-EXTRA'],loc='upper right',fontsize='large') \n",
    "plt.xlabel('iterations',fontsize= 'x-large')\n",
    "plt.ylabel('NMSE',fontsize= 'x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\\n    _,pred_PGEXTRA,pred_PGEXTRA_hist = model_PGEXTRA(W, A, y, pyg_data,num_layers)\\n    _,pred_DGD,pred_DGD_hist = model_DGD(W, A, y, pyg_data,num_layers)\\n    \\n    original_PGEXTRA,original_PGEXTRA_hist = torch_PGEXTRA(W, A, y, num_layers,0.002 \\t 2 )\\n    original_DGD, original_DGD_hist = torch_DGD(W, A, y, num_layers,0.001,0.05)\\n    original_NIDS, original_NIDS_hist = torch_NIDS(W, A, y, num_layers,0.005,0.5 ,7 )\\n\\n\\norigin_PGEXTRA_error = hist_nmse(original_PGEXTRA_hist,x_true)\\norigin_DGD_error = hist_nmse(original_DGD_hist,x_true)\\norigin_NIDS_error = hist_nmse(original_NIDS_hist,x_true)\\npred_PGEXTRA_error = hist_nmse(pred_PGEXTRA_hist,x_true)\\npred_DGD_error = hist_nmse(pred_DGD_hist,x_true)\\n\\n#plt.rc('text',usetex=True)nn\\n\\nx = [i for i in range(num_layers+1)]\\nplt.plot(x,origin_DGD_error[:num_layers+1])\\nplt.plot(x,origin_PGEXTRA_error[:num_layers+1])\\nplt.plot(x,origin_NIDS_error[:num_layers+1])\\n\\nplt.plot(x,pred_DGD_error[:num_layers+1])\\nplt.plot(x,pred_PGEXTRA_error[:num_layers+1])\\n\\n\\nplt.legend(['Prox-DGD','PG-EXTRA','NIDS','GNN-Prox-DGD','GNN-PG-EXTRA'],loc='upper right',fontsize='x-large') \\nplt.xlabel('iterations',fontsize= 'x-large')\\nplt.ylabel('NMSE',fontsize= 'x-large')\\n\\nplt.show()\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "    _,pred_PGEXTRA,pred_PGEXTRA_hist = model_PGEXTRA(W, A, y, pyg_data,num_layers)\n",
    "    _,pred_DGD,pred_DGD_hist = model_DGD(W, A, y, pyg_data,num_layers)\n",
    "    \n",
    "    original_PGEXTRA,original_PGEXTRA_hist = torch_PGEXTRA(W, A, y, num_layers,0.002 \t 2 )\n",
    "    original_DGD, original_DGD_hist = torch_DGD(W, A, y, num_layers,0.001,0.05)\n",
    "    original_NIDS, original_NIDS_hist = torch_NIDS(W, A, y, num_layers,0.005,0.5 ,7 )\n",
    "\n",
    "\n",
    "origin_PGEXTRA_error = hist_nmse(original_PGEXTRA_hist,x_true)\n",
    "origin_DGD_error = hist_nmse(original_DGD_hist,x_true)\n",
    "origin_NIDS_error = hist_nmse(original_NIDS_hist,x_true)\n",
    "pred_PGEXTRA_error = hist_nmse(pred_PGEXTRA_hist,x_true)\n",
    "pred_DGD_error = hist_nmse(pred_DGD_hist,x_true)\n",
    "\n",
    "#plt.rc('text',usetex=True)nn\n",
    "\n",
    "x = [i for i in range(num_layers+1)]\n",
    "plt.plot(x,origin_DGD_error[:num_layers+1])\n",
    "plt.plot(x,origin_PGEXTRA_error[:num_layers+1])\n",
    "plt.plot(x,origin_NIDS_error[:num_layers+1])\n",
    "\n",
    "plt.plot(x,pred_DGD_error[:num_layers+1])\n",
    "plt.plot(x,pred_PGEXTRA_error[:num_layers+1])\n",
    "\n",
    "\n",
    "plt.legend(['Prox-DGD','PG-EXTRA','NIDS','GNN-Prox-DGD','GNN-PG-EXTRA'],loc='upper right',fontsize='x-large') \n",
    "plt.xlabel('iterations',fontsize= 'x-large')\n",
    "plt.ylabel('NMSE',fontsize= 'x-large')\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = SynDataset(test_num)\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False, collate_fn=collate)\n",
    "for iter, (W, A, y, x_true,pyg_data) in enumerate(test_loader):\n",
    "    _,pred_PGEXTRA,pred_PGEXTRA_hist = model_PGEXTRA(W, A, y, pyg_data,num_layers)\n",
    "    _,pred_DGD,pred_DGD_hist = model_DGD(W, A, y, pyg_data,num_layers)\n",
    "    #_,pred_NIDS,pred_NIDS_hist = model_NIDS(W, A, y, pyg_data,num_layers)\n",
    "    \n",
    "    original_PGEXTRA,original_PGEXTRA_hist = torch_PGEXTRA(W, A, y, 500,0.005,0.5)\n",
    "    original_DGD, original_DGD_hist = torch_DGD(W, A, y, 500,0.005,0.5)\n",
    "    #original_NIDS, original_NIDS_hist = torch_NIDS(W, A, y, 200,0.005,0.01)\n",
    "\n",
    "\n",
    "origin_PGEXTRA_error = hist_nmse(original_PGEXTRA_hist,x_true)\n",
    "origin_DGD_error = hist_nmse(original_DGD_hist,x_true)\n",
    "#origin_NIDS_error = hist_nmse(original_NIDS_hist,x_true)\n",
    "pred_PGEXTRA_error = hist_nmse(pred_PGEXTRA_hist,x_true)\n",
    "pred_DGD_error = hist_nmse(pred_DGD_hist,x_true)\n",
    "#pred_NIDS_error = hist_nmse(pred_NIDS_hist,x_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"D\"+str(n)+\"M\"+str(m)+\"NO\"+str(nnz)\n",
    "writer_error=pd.ExcelWriter(\"./error_fig/noise3/\"+figure_name+\".xls\")\n",
    "df_error= pd.DataFrame({'PG-EXTRA':origin_PGEXTRA_error,'DGD':origin_DGD_error})\n",
    "df_error.to_excel(writer_error,sheet_name='Origin')\n",
    "    \n",
    "df_feasibility= pd.DataFrame({'PG-EXTRA':pred_PGEXTRA_error,'DGD':pred_DGD_error})\n",
    "df_feasibility.to_excel(writer_error,sheet_name='GNN')\n",
    "writer_error.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.rc('text',usetex=True)nn\n",
    "#plt.xscale('log')\n",
    "#mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "long_end = 200\n",
    "x_long = [i for i in range(long_end+1)]\n",
    "plt.plot(x_long,origin_DGD_error[:long_end+1],linewidth=2,linestyle='--',color = 'tab:red')\n",
    "plt.plot(x_long,origin_PGEXTRA_error[:long_end+1],linewidth=2,linestyle='--',color = 'tab:blue' )\n",
    "#plt.plot(x_long,origin_NIDS_error[:long_end+1],linewidth=3)\n",
    "\n",
    "x = [i for i in range(num_layers+1)]\n",
    "plt.plot(x,pred_DGD_error[:num_layers+1],linewidth=2,color = 'tab:red')\n",
    "plt.plot(x,pred_PGEXTRA_error[:num_layers+1],linewidth=2,color = 'tab:blue')\n",
    "#plt.plot(x,pred_NIDS_error[:num_layers+1],linewidth=3)\n",
    "\n",
    "plt.legend(['Prox-DGD','PG-EXTRA','GNN-Prox-DGD','GNN-PG-EXTRA'],loc='upper right',fontsize='large') \n",
    "plt.xlabel('iterations',fontsize= 'x-large')\n",
    "plt.ylabel('NMSE',fontsize= 'x-large')\n",
    "\n",
    "figure_name = \"D\"+str(n)+\"M\"+str(m)+\"NO\"+str(nnz)\n",
    "plt.savefig(\"./error_fig/noise3/\"+figure_name+\".eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
