{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiezhq/.wanghe_env/lib/python3.7/site-packages/torch_sparse/tensor.py:46: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  index = mat.nonzero()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import copy\n",
    "import pandas as pd\n",
    "import xlwt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_nodes = 5\n",
    "num_edges = 6\n",
    "n = 100\n",
    "m = 80\n",
    "k = 16\n",
    "train_num = 1000\n",
    "test_num = 100\n",
    "num_layers = 50\n",
    "nnz = 8\n",
    "\n",
    "#less nnz =5; m = 50; k = 10\n",
    "\n",
    "def metropolis(adjacency_matrix):\n",
    "    num_of_nodes = adjacency_matrix.shape[0]\n",
    "    metropolis=np.zeros((num_of_nodes,num_of_nodes))\n",
    "    for i in range(num_of_nodes):\n",
    "        for j in range(num_of_nodes):\n",
    "            if adjacency_matrix[i,j]==1:\n",
    "                d_i = np.sum(adjacency_matrix[i,:])\n",
    "                d_j = np.sum(adjacency_matrix[j,:])\n",
    "                metropolis[i,j]=1/(1+max(d_i,d_j))\n",
    "        metropolis[i,i]=1-sum(metropolis[i,:])\n",
    "    return metropolis\n",
    "\n",
    "class SynDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "        self.A = []; \n",
    "        self.y = []; \n",
    "        self.x_true = []\n",
    "        self.pyg_data=[]\n",
    "        self.process()\n",
    "        \n",
    "        \n",
    "    def gen_func(self, num_of_nodes, n, m, k):\n",
    "        A_all = np.random.randn(m, n)\n",
    "        x = np.random.randn(n)\n",
    "        x_norm = 0\n",
    "\n",
    "        while(x_norm < 1e-2):\n",
    "            x_mask = np.random.rand(n)\n",
    "            x_mask[x_mask < 1 - nnz/100] = 0\n",
    "            x_mask[x_mask > 0] = 1\n",
    "            x_norm = np.linalg.norm(x * x_mask)\n",
    "\n",
    "        x = x * x_mask\n",
    "        x = x/np.linalg.norm(x)\n",
    "        \n",
    "        SNR_db = 30\n",
    "        SNR = 10**(SNR_db/10)\n",
    "        \n",
    "        noise = np.random.randn(m) * np.sqrt(1/SNR)\n",
    "        y_all = A_all@x + noise\n",
    "\n",
    "        A = np.zeros((num_of_nodes, k , n))\n",
    "        y = np.zeros((num_of_nodes, k))\n",
    "        for ii in range(num_of_nodes):\n",
    "            start = (k*ii) % m; end = (k*(ii+1) )%m\n",
    "            if(start > end):\n",
    "                A[ii,:,:] = np.concatenate((A_all[start:,:],A_all[:end,:]), axis = 0)\n",
    "                y[ii,:] = np.concatenate((np.expand_dims(y_all[start:], axis = 0), \n",
    "                                          np.expand_dims(y_all[:end], axis = 0)), axis = 1)\n",
    "            else:\n",
    "                A[ii,:,:] = A_all[start:end,:]\n",
    "                y[ii,:] = np.expand_dims(y_all[start:end], axis = 0)\n",
    "                \n",
    "        x = np.expand_dims(x, axis = 0)\n",
    "        x = x.repeat(num_of_nodes, axis = 0)\n",
    "        \n",
    "        return A, y, x\n",
    "\n",
    "    def gen_graph(self, num_of_nodes, num_of_edges, directed=False, add_self_loops=True):\n",
    "        G = nx.gnm_random_graph(num_of_nodes, num_of_edges, directed=directed)\n",
    "        k = 0\n",
    "        while (nx.is_strongly_connected(G) if directed else nx.is_connected(G)) == False:\n",
    "            G = nx.gnm_random_graph(num_of_nodes, num_of_edges, directed=directed)\n",
    "            k += 1\n",
    "        # print(\"Check if connected: \", nx.is_connected(G))\n",
    "        # nx.draw(G)\n",
    "        \n",
    "        edge_index = from_networkx(G).edge_index\n",
    "        adj = nx.to_numpy_matrix(G)\n",
    "        return G, adj,edge_index\n",
    "        \n",
    "    def process(self):\n",
    "        _, adj,edge_index = self.gen_graph(num_nodes, num_edges)\n",
    "        self.edge_index = edge_index\n",
    "        W = metropolis(adj)\n",
    "        self.W = [torch.tensor(W, dtype = torch.float)] * self.samples\n",
    "        \n",
    "        \n",
    "        for ii in range(self.samples):\n",
    "            A, y, x_true = self.gen_func(num_nodes, n, m, k)\n",
    "            self.A.append(torch.tensor(A, dtype = torch.float) ); \n",
    "            self.y.append(torch.tensor(y, dtype = torch.float) ); \n",
    "            self.x_true.append(torch.tensor(x_true, dtype = torch.float) )\n",
    "            \n",
    "            edge_weight=torch.tensor(W,dtype=torch.float)\n",
    "            self.pyg_data.append(Data(edge_weight=SparseTensor.from_dense(edge_weight)))        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.W[idx], self.A[idx], self.y[idx], self.x_true[idx], self.pyg_data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of graphs in the dataset\"\"\"\n",
    "        return len(self.A)\n",
    "    \n",
    "    \n",
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    W, A, y, x_true, pyg_data = map(list, zip(*samples))\n",
    "    W = torch.stack(W)\n",
    "    A = torch.stack(A)\n",
    "    y = torch.stack(y)\n",
    "    x_true = torch.stack(x_true)\n",
    "    pyg_data = Batch.from_data_list(pyg_data)\n",
    "    return W, A, y, x_true, pyg_data\n",
    "class MetropolisConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super(MetropolisConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "\n",
    "    def forward(self, x, pyg_data):\n",
    "        (B, N, D)=x.shape\n",
    "        out = self.propagate(x=x.view(-1,D), edge_index=pyg_data.edge_weight, node_dim=-1)\n",
    "        return out.view(B,N,D)\n",
    "\n",
    "    def message_and_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "def step_loss(gamma,x, y):\n",
    "    #gamma = 0.75\n",
    "    n_steps = x.shape[0]\n",
    "    #print(n_steps)\n",
    "    di = torch.ones((n_steps)) * gamma\n",
    "    power = torch.tensor(range(n_steps, 0, -1))\n",
    "    gamma_a = di ** power\n",
    "    gamma_a = gamma_a.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    y = torch.unsqueeze(y, axis = 0)\n",
    "    ele_loss = gamma_a * (x - y) **2\n",
    "    #print(ele_loss.shape)\n",
    "    #print(torch.mean(ele_loss,  (1,2,3) ))\n",
    "    loss = torch.mean(ele_loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "train_data = SynDataset(train_num)\n",
    "\n",
    "test_data = SynDataset(test_num)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN-PGEXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006986133785176207 tensor(0.0093, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "0.00012015691663691541 tensor(0.0041, grad_fn=<SelectBackward>) tensor(-0.0009, grad_fn=<SelectBackward>)\n",
      "8.623260691820178e-05 tensor(0.0024, grad_fn=<SelectBackward>) tensor(-1.3205e-05, grad_fn=<SelectBackward>)\n",
      "6.412451762116689e-05 tensor(0.0025, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "5.2622512839661795e-05 tensor(0.0026, grad_fn=<SelectBackward>) tensor(0.0002, grad_fn=<SelectBackward>)\n",
      "4.851970754771173e-05 tensor(0.0026, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "4.4501045522338245e-05 tensor(0.0026, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "4.263982395968924e-05 tensor(0.0026, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "4.065322173119057e-05 tensor(0.0026, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "3.926794988728943e-05 tensor(0.0026, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "3.791956851273426e-05 tensor(0.0025, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "3.6790817716791935e-05 tensor(0.0024, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "3.5174559570805286e-05 tensor(0.0023, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "3.385303153891073e-05 tensor(0.0022, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "3.269620719947852e-05 tensor(0.0020, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "3.2758120028120175e-05 tensor(0.0017, grad_fn=<SelectBackward>) tensor(0.0001, grad_fn=<SelectBackward>)\n",
      "3.170488179193853e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(3.6092e-05, grad_fn=<SelectBackward>)\n",
      "3.1306422158650093e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0001, grad_fn=<SelectBackward>)\n",
      "3.0435381859206245e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0001, grad_fn=<SelectBackward>)\n",
      "2.9783966169816267e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0002, grad_fn=<SelectBackward>)\n",
      "2.9163896272166312e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "2.866159803716073e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "2.8137820720530726e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "2.7916246779113862e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "2.738468134566574e-05 tensor(0.0017, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "2.7339344853771763e-05 tensor(0.0018, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "2.6953913049965195e-05 tensor(0.0019, grad_fn=<SelectBackward>) tensor(0.0006, grad_fn=<SelectBackward>)\n",
      "3.488612492219545e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(2.8332e-05, grad_fn=<SelectBackward>)\n",
      "3.235672357959629e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(2.9870e-05, grad_fn=<SelectBackward>)\n",
      "3.1560192837787326e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(3.1639e-05, grad_fn=<SelectBackward>)\n",
      "3.099829967823098e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(3.3601e-05, grad_fn=<SelectBackward>)\n",
      "3.069737016403451e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(3.6181e-05, grad_fn=<SelectBackward>)\n",
      "3.0231422272208874e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(3.9083e-05, grad_fn=<SelectBackward>)\n",
      "2.973949847273616e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(4.1993e-05, grad_fn=<SelectBackward>)\n",
      "2.9430349115955323e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(4.5767e-05, grad_fn=<SelectBackward>)\n",
      "2.9126389790690155e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(4.9603e-05, grad_fn=<SelectBackward>)\n",
      "2.9094566741605377e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(5.2733e-05, grad_fn=<SelectBackward>)\n",
      "2.8721103774387302e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(5.6901e-05, grad_fn=<SelectBackward>)\n",
      "2.8416127861419227e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(6.0920e-05, grad_fn=<SelectBackward>)\n",
      "2.8223288438766758e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(6.4743e-05, grad_fn=<SelectBackward>)\n",
      "2.814489499769479e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(6.9457e-05, grad_fn=<SelectBackward>)\n",
      "2.7911388144730154e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(7.3993e-05, grad_fn=<SelectBackward>)\n",
      "2.759811161467951e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(7.8793e-05, grad_fn=<SelectBackward>)\n",
      "2.7677251125624025e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(8.3144e-05, grad_fn=<SelectBackward>)\n",
      "2.750415410446294e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(8.7539e-05, grad_fn=<SelectBackward>)\n",
      "2.7404297952671186e-05 tensor(0.0016, grad_fn=<SelectBackward>) tensor(9.3175e-05, grad_fn=<SelectBackward>)\n",
      "2.73394338705657e-05 tensor(0.0017, grad_fn=<SelectBackward>) tensor(9.8559e-05, grad_fn=<SelectBackward>)\n",
      "2.7145543526785332e-05 tensor(0.0017, grad_fn=<SelectBackward>) tensor(0.0001, grad_fn=<SelectBackward>)\n",
      "2.7076275898707536e-05 tensor(0.0017, grad_fn=<SelectBackward>) tensor(0.0001, grad_fn=<SelectBackward>)\n",
      "2.7235628579092008e-05 tensor(0.0017, grad_fn=<SelectBackward>) tensor(0.0001, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Net_PGEXTRA(torch.nn.Module):\n",
    "    def __init__(self, step_size, num_layers):\n",
    "        super(Net_PGEXTRA, self).__init__()\n",
    "        self.step_size = nn.Parameter(torch.ones(num_layers)*step_size)\n",
    "        self.lam = nn.Parameter(torch.ones(num_layers)*step_size*10)\n",
    "        self.num_layers = num_layers\n",
    "        self.conv=MetropolisConv()\n",
    "    def tgrad_qp(self, A, b, x):\n",
    "        # A: nodes * k * n\n",
    "        # X: nodes * n\n",
    "        # Y: nodes * k\n",
    "        '''grad_A = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            grad_A[i] = A[i].T @ (A[i] @ x[i] - b[i])\n",
    "        return grad_A'''\n",
    "        x_ = torch.unsqueeze(x, axis = -1)\n",
    "        b_ = torch.unsqueeze(b, axis = -1)\n",
    "\n",
    "        A_t = A.transpose(2,3)\n",
    "        grad_A = A_t @ (A @ x_ - b_)\n",
    "        #print(A.shape, x.shape, b.shape)\n",
    "        #print(grad_A.shape)\n",
    "        grad_A = torch.squeeze(grad_A, axis = -1)\n",
    "        #print(grad_A.shape)\n",
    "        return grad_A\n",
    "    \n",
    "    def act(self, x, ii):\n",
    "        tau = self.lam[ii] #* self.step_size[ii]\n",
    "        return F.relu(x - tau) - F.relu( - x - tau)\n",
    "            \n",
    "    def forward(self, W, A, b,pyg_data, max_iter):\n",
    "        (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "        init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "        ret_z = []\n",
    "        \n",
    "        k = 1\n",
    "        x_0 = init_x\n",
    "        x_12 = self.conv(x_0,pyg_data) - self.step_size[0] * self.tgrad_qp(A, b, x_0)\n",
    "        x_1 = self.act(x_12, 0)\n",
    "        \n",
    "        x_hist = [init_x,x_1]\n",
    "        while (k < max_iter):\n",
    "            x_32 = self.conv(x_1,pyg_data) + x_12 - (self.conv(x_0,pyg_data) + x_0)/2 - \\\n",
    "                self.step_size[k] * (self.tgrad_qp(A, b, x_1)-self.tgrad_qp(A, b, x_0))\n",
    "            x_2 = self.act(x_32, k)\n",
    "            \n",
    "            ret_z.append(x_2)\n",
    "\n",
    "            x_0 = x_1\n",
    "            x_1 = x_2\n",
    "            x_12 = x_32\n",
    "\n",
    "            k = k + 1\n",
    "            x_hist.append(x_2)\n",
    "        \n",
    "        ret_z = torch.stack(ret_z)\n",
    "        return ret_z, x_2,x_hist\n",
    "      \n",
    "###main\n",
    "model_PGEXTRA = Net_PGEXTRA(1e-3, num_layers)\n",
    "optimizer = optim.Adam(model_PGEXTRA.parameters(), lr=2e-5)\n",
    "model_PGEXTRA.train()\n",
    "epoch_losses = []\n",
    "for epoch in range(500):\n",
    "    epoch_loss = 0\n",
    "    for iter, (W, A, y, x_true,pyg_data) in enumerate(train_loader):\n",
    "        z, _,_ = model_PGEXTRA(W, A, y, pyg_data,num_layers)\n",
    "        loss = step_loss(0.84,z, x_true)\n",
    "        #best 83\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch_loss, model_PGEXTRA.lam[1], model_PGEXTRA.step_size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN-DGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007493804750993149 tensor(0.0093, grad_fn=<SelectBackward>) tensor(0.0016, grad_fn=<SelectBackward>)\n",
      "0.00019100837835139828 tensor(0.0071, grad_fn=<SelectBackward>) tensor(0.0050, grad_fn=<SelectBackward>)\n",
      "0.00015175550970525364 tensor(0.0096, grad_fn=<SelectBackward>) tensor(0.0059, grad_fn=<SelectBackward>)\n",
      "0.00014586906490876572 tensor(0.0103, grad_fn=<SelectBackward>) tensor(0.0058, grad_fn=<SelectBackward>)\n",
      "0.0001485099460296624 tensor(0.0110, grad_fn=<SelectBackward>) tensor(0.0055, grad_fn=<SelectBackward>)\n",
      "0.00014119377283350332 tensor(0.0110, grad_fn=<SelectBackward>) tensor(0.0057, grad_fn=<SelectBackward>)\n",
      "0.0001406069532094989 tensor(0.0113, grad_fn=<SelectBackward>) tensor(0.0055, grad_fn=<SelectBackward>)\n",
      "0.0001372662952690007 tensor(0.0113, grad_fn=<SelectBackward>) tensor(0.0058, grad_fn=<SelectBackward>)\n",
      "0.00013631668252855889 tensor(0.0116, grad_fn=<SelectBackward>) tensor(0.0056, grad_fn=<SelectBackward>)\n",
      "0.0001456634408896207 tensor(0.0123, grad_fn=<SelectBackward>) tensor(0.0051, grad_fn=<SelectBackward>)\n",
      "0.00014277505692916748 tensor(0.0122, grad_fn=<SelectBackward>) tensor(0.0052, grad_fn=<SelectBackward>)\n",
      "0.00014082989991948125 tensor(0.0122, grad_fn=<SelectBackward>) tensor(0.0052, grad_fn=<SelectBackward>)\n",
      "0.00013989106741973956 tensor(0.0122, grad_fn=<SelectBackward>) tensor(0.0053, grad_fn=<SelectBackward>)\n",
      "0.0001378425208713452 tensor(0.0122, grad_fn=<SelectBackward>) tensor(0.0053, grad_fn=<SelectBackward>)\n",
      "0.000137180879164589 tensor(0.0121, grad_fn=<SelectBackward>) tensor(0.0054, grad_fn=<SelectBackward>)\n",
      "0.00013501506759894255 tensor(0.0121, grad_fn=<SelectBackward>) tensor(0.0055, grad_fn=<SelectBackward>)\n",
      "0.00013315437581695733 tensor(0.0121, grad_fn=<SelectBackward>) tensor(0.0055, grad_fn=<SelectBackward>)\n",
      "0.0001342215166459937 tensor(0.0120, grad_fn=<SelectBackward>) tensor(0.0056, grad_fn=<SelectBackward>)\n",
      "0.00013199667569097073 tensor(0.0121, grad_fn=<SelectBackward>) tensor(0.0056, grad_fn=<SelectBackward>)\n",
      "0.00013163664652893203 tensor(0.0121, grad_fn=<SelectBackward>) tensor(0.0056, grad_fn=<SelectBackward>)\n",
      "0.00012958295769749384 tensor(0.0122, grad_fn=<SelectBackward>) tensor(0.0056, grad_fn=<SelectBackward>)\n",
      "0.000129243002675139 tensor(0.0123, grad_fn=<SelectBackward>) tensor(0.0055, grad_fn=<SelectBackward>)\n",
      "0.00012820223810194875 tensor(0.0123, grad_fn=<SelectBackward>) tensor(0.0055, grad_fn=<SelectBackward>)\n",
      "0.00012583143984556955 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0054, grad_fn=<SelectBackward>)\n",
      "0.00012156375146332721 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0054, grad_fn=<SelectBackward>)\n",
      "0.00011954254046031565 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0051, grad_fn=<SelectBackward>)\n",
      "0.00011653489264062955 tensor(0.0126, grad_fn=<SelectBackward>) tensor(0.0049, grad_fn=<SelectBackward>)\n",
      "0.0001109400534460292 tensor(0.0126, grad_fn=<SelectBackward>) tensor(0.0047, grad_fn=<SelectBackward>)\n",
      "0.00010294363391949446 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0049, grad_fn=<SelectBackward>)\n",
      "9.636382651478925e-05 tensor(0.0125, grad_fn=<SelectBackward>) tensor(0.0049, grad_fn=<SelectBackward>)\n",
      "9.15141322366253e-05 tensor(0.0125, grad_fn=<SelectBackward>) tensor(0.0049, grad_fn=<SelectBackward>)\n",
      "8.622594282314822e-05 tensor(0.0125, grad_fn=<SelectBackward>) tensor(0.0048, grad_fn=<SelectBackward>)\n",
      "8.106120276352158e-05 tensor(0.0125, grad_fn=<SelectBackward>) tensor(0.0047, grad_fn=<SelectBackward>)\n",
      "7.694645091760322e-05 tensor(0.0126, grad_fn=<SelectBackward>) tensor(0.0045, grad_fn=<SelectBackward>)\n",
      "7.202162339581264e-05 tensor(0.0125, grad_fn=<SelectBackward>) tensor(0.0043, grad_fn=<SelectBackward>)\n",
      "6.829183996615029e-05 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0042, grad_fn=<SelectBackward>)\n",
      "6.482485616743361e-05 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0039, grad_fn=<SelectBackward>)\n",
      "6.163963905692071e-05 tensor(0.0123, grad_fn=<SelectBackward>) tensor(0.0034, grad_fn=<SelectBackward>)\n",
      "6.722519697177631e-05 tensor(0.0123, grad_fn=<SelectBackward>) tensor(0.0030, grad_fn=<SelectBackward>)\n",
      "5.9205009506513306e-05 tensor(0.0124, grad_fn=<SelectBackward>) tensor(0.0022, grad_fn=<SelectBackward>)\n",
      "5.710730192731717e-05 tensor(0.0125, grad_fn=<SelectBackward>) tensor(0.0013, grad_fn=<SelectBackward>)\n",
      "5.457678139464406e-05 tensor(0.0129, grad_fn=<SelectBackward>) tensor(0.0005, grad_fn=<SelectBackward>)\n",
      "5.208276286339242e-05 tensor(0.0138, grad_fn=<SelectBackward>) tensor(0.0002, grad_fn=<SelectBackward>)\n",
      "5.039135282913776e-05 tensor(0.0153, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "4.844232341838506e-05 tensor(0.0172, grad_fn=<SelectBackward>) tensor(0.0003, grad_fn=<SelectBackward>)\n",
      "4.5950812364026206e-05 tensor(0.0195, grad_fn=<SelectBackward>) tensor(0.0002, grad_fn=<SelectBackward>)\n",
      "4.474553759337141e-05 tensor(0.0221, grad_fn=<SelectBackward>) tensor(0.0002, grad_fn=<SelectBackward>)\n",
      "4.2446028260201274e-05 tensor(0.0250, grad_fn=<SelectBackward>) tensor(8.6201e-05, grad_fn=<SelectBackward>)\n",
      "4.1693557705002604e-05 tensor(0.0283, grad_fn=<SelectBackward>) tensor(0.0004, grad_fn=<SelectBackward>)\n",
      "3.9606113659829134e-05 tensor(0.0306, grad_fn=<SelectBackward>) tensor(-4.5120e-05, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "class Net_DGD(torch.nn.Module):\n",
    "    def __init__(self, step_size, num_layers):\n",
    "        super(Net_DGD, self).__init__()\n",
    "        self.step_size = nn.Parameter(torch.ones(num_layers)*step_size)\n",
    "        self.lam = nn.Parameter(torch.ones(num_layers)*step_size*10)\n",
    "        self.num_layers = num_layers\n",
    "        self.conv=MetropolisConv()\n",
    "    def tgrad_qp(self, A, b, x):\n",
    "        # A: nodes * k * n\n",
    "        # X: nodes * n\n",
    "        # Y: nodes * k\n",
    "        '''grad_A = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            grad_A[i] = A[i].T @ (A[i] @ x[i] - b[i])\n",
    "        return grad_A'''\n",
    "        x_ = torch.unsqueeze(x, axis = -1)\n",
    "        b_ = torch.unsqueeze(b, axis = -1)\n",
    "\n",
    "        A_t = A.transpose(2,3)\n",
    "        grad_A = A_t @ (A @ x_ - b_)\n",
    "        #print(A.shape, x.shape, b.shape)\n",
    "        #print(grad_A.shape)\n",
    "        grad_A = torch.squeeze(grad_A, axis = -1)\n",
    "        #print(grad_A.shape)\n",
    "        return grad_A\n",
    "    \n",
    "    def act(self, x, ii):\n",
    "        tau = self.lam[ii] #* self.step_size[ii]\n",
    "        return F.relu(x - tau) - F.relu( - x - tau)\n",
    "            \n",
    "    def forward(self, W, A, b,pyg_data, max_iter):\n",
    "        (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "        init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "        ret_z = []\n",
    "        \n",
    "        k = 1\n",
    "        x_0 = init_x\n",
    "        x_12 = self.conv(x_0,pyg_data) - self.step_size[0] * self.tgrad_qp(A, b, x_0)\n",
    "        x_1 = self.act(x_12, 0)\n",
    "        \n",
    "        x_hist = [init_x,x_1]\n",
    "        while (k < max_iter):\n",
    "            #x_32 = self.conv(x_1,pyg_data) + x_12 - (self.conv(x_0,pyg_data) + x_0)/2 - \\\n",
    "            #    self.step_size[k] * (self.tgrad_qp(A, b, x_1)-self.tgrad_qp(A, b, x_0))\n",
    "            x_32 = self.conv(x_1,pyg_data) - self.step_size[k] * self.tgrad_qp(A, b, x_1)\n",
    "            x_2 = self.act(x_32, k)\n",
    "            \n",
    "            ret_z.append(x_2)\n",
    "\n",
    "            x_0 = x_1\n",
    "            x_1 = x_2\n",
    "            x_12 = x_32\n",
    "\n",
    "            k = k + 1\n",
    "            x_hist.append(x_2)\n",
    "        \n",
    "        ret_z = torch.stack(ret_z)\n",
    "        return ret_z, x_2,x_hist\n",
    "def step_loss(gamma,x, y):\n",
    "    #gamma = 0.75\n",
    "    n_steps = x.shape[0]\n",
    "    #print(n_steps)\n",
    "    #di = torch.ones((n_steps)) * gamma\n",
    "    power = torch.tensor(range(n_steps, 0, -1))\n",
    "    gamma_a = 1/ power\n",
    "    gamma_a = gamma_a.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    y = torch.unsqueeze(y, axis = 0)\n",
    "    ele_loss = gamma_a * (x - y) **2\n",
    "    #print(ele_loss.shape)\n",
    "    #print(torch.mean(ele_loss,  (1,2,3) ))\n",
    "    loss = torch.mean(ele_loss)\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "model_DGD = Net_DGD(1e-3, num_layers)\n",
    "optimizer = optim.Adam(model_DGD.parameters(), lr=2e-5)\n",
    "model_DGD.train()\n",
    "epoch_losses = []\n",
    "for epoch in range(500):\n",
    "    epoch_loss = 0\n",
    "    for iter, (W, A, y, x_true,pyg_data) in enumerate(train_loader):\n",
    "        z, _,_ = model_DGD(W, A, y, pyg_data,num_layers)\n",
    "        loss = step_loss(0.907,z, x_true)\n",
    "        #best 905\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch_loss, model_DGD.lam[1], model_DGD.step_size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Net_NIDS(torch.nn.Module):\\n    def __init__(self, step_size, num_layers, num_nodes):\\n        super(Net_NIDS, self).__init__()\\n        self.step_size = nn.Parameter(torch.ones(num_layers,num_nodes)*step_size)\\n        self.lam = nn.Parameter(torch.ones(num_layers,num_nodes)*step_size*10)\\n        self.c = nn.Parameter(torch.ones(num_layers)*step_size)\\n        self.num_layers = num_layers\\n        self.conv=MetropolisConv()\\n        \\n    def tgrad_qp(self, A, b, x):\\n        # A: nodes * k * n\\n        # X: nodes * n\\n        # Y: nodes * k\\n\\n        x_ = torch.unsqueeze(x, axis = -1)\\n        b_ = torch.unsqueeze(b, axis = -1)\\n\\n        A_t = A.transpose(2,3)\\n        grad_A = A_t @ (A @ x_ - b_)\\n        grad_A = torch.squeeze(grad_A, axis = -1)\\n        return grad_A\\n    \\n    def act(self, x, ii):\\n        tau = (self.lam[ii]).unsqueeze(0).unsqueeze(-1) #* self.step_size[ii]\\n        return F.relu(x - tau) - F.relu( - x - tau)\\n            \\n    def forward(self, W, A, b,pyg_data, max_iter):\\n        (batch_size, num_of_nodes, _, dim) = A.shape\\n        init_x = torch.zeros((batch_size, num_of_nodes, dim))\\n        ret_z = []\\n        \\n        k = 1\\n        x_0 = init_x\\n        x_12 = x_0 - torch.diag(self.step_size[0]).unsqueeze(0)@ self.tgrad_qp(A, b, x_0)\\n        x_1 = self.act(x_12, 0)\\n        \\n        x_hist = [init_x,x_1]\\n        \\n        while (k < max_iter):\\n            c = self.c[k]/(2*torch.max(self.step_size[k]))\\n            #W_hat = torch.eye(num_of_nodes).unsqueeze(0)- c*torch.diag(self.step_size[k]).unsqueeze(0)@(torch.eye(num_of_nodes).unsqueeze(0)- W)\\n            #print(W_hat)\\n            temp = 2*x_1-x_0 - torch.diag(self.step_size[k])@(self.tgrad_qp(A, b, x_1)-self.tgrad_qp(A, b, x_0))\\n            conv_result = self.conv(temp,pyg_data)\\n            x_32 = x_12 - x_1 + temp - c*torch.diag(self.step_size[k]).unsqueeze(0)@ (temp - conv_result)\\n            #x_32 = x_12-x_1 + self.conv(temp,pyg_data)\\n            #x_32 =x_12 - x_1 + w@temp\\n            x_2 = self.act(x_32, k)\\n            \\n            ret_z.append(x_2)\\n\\n            x_0 = x_1\\n            x_1 = x_2\\n            x_12 = x_32\\n            \\n\\n            k = k + 1\\n            x_hist.append(x_2)\\n        \\n        ret_z = torch.stack(ret_z)\\n        return ret_z, x_2,x_hist\\nmodel_NIDS = Net_NIDS(1e-3, num_layers,num_nodes)\\noptimizer = optim.Adam(model_NIDS.parameters(), lr=1e-4)\\nmodel_NIDS.train()\\nepoch_losses = []\\nfor epoch in range(500):\\n    epoch_loss = 0\\n    for iter, (W, A, y, x_true,pyg_data) in enumerate(train_loader):\\n        z, _,_ = model_NIDS(W, A, y, pyg_data,num_layers)\\n        loss = step_loss(0.83,z, x_true)\\n        \\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n        epoch_loss += loss.detach().item()\\n    epoch_loss /= (iter + 1)\\n    if(epoch % 10 == 0):\\n        print(epoch_loss, model_NIDS.lam[1], model_NIDS.step_size[1])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Net_NIDS(torch.nn.Module):\n",
    "    def __init__(self, step_size, num_layers, num_nodes):\n",
    "        super(Net_NIDS, self).__init__()\n",
    "        self.step_size = nn.Parameter(torch.ones(num_layers,num_nodes)*step_size)\n",
    "        self.lam = nn.Parameter(torch.ones(num_layers,num_nodes)*step_size*10)\n",
    "        self.c = nn.Parameter(torch.ones(num_layers)*step_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.conv=MetropolisConv()\n",
    "        \n",
    "    def tgrad_qp(self, A, b, x):\n",
    "        # A: nodes * k * n\n",
    "        # X: nodes * n\n",
    "        # Y: nodes * k\n",
    "\n",
    "        x_ = torch.unsqueeze(x, axis = -1)\n",
    "        b_ = torch.unsqueeze(b, axis = -1)\n",
    "\n",
    "        A_t = A.transpose(2,3)\n",
    "        grad_A = A_t @ (A @ x_ - b_)\n",
    "        grad_A = torch.squeeze(grad_A, axis = -1)\n",
    "        return grad_A\n",
    "    \n",
    "    def act(self, x, ii):\n",
    "        tau = (self.lam[ii]).unsqueeze(0).unsqueeze(-1) #* self.step_size[ii]\n",
    "        return F.relu(x - tau) - F.relu( - x - tau)\n",
    "            \n",
    "    def forward(self, W, A, b,pyg_data, max_iter):\n",
    "        (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "        init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "        ret_z = []\n",
    "        \n",
    "        k = 1\n",
    "        x_0 = init_x\n",
    "        x_12 = x_0 - torch.diag(self.step_size[0]).unsqueeze(0)@ self.tgrad_qp(A, b, x_0)\n",
    "        x_1 = self.act(x_12, 0)\n",
    "        \n",
    "        x_hist = [init_x,x_1]\n",
    "        \n",
    "        while (k < max_iter):\n",
    "            c = self.c[k]/(2*torch.max(self.step_size[k]))\n",
    "            #W_hat = torch.eye(num_of_nodes).unsqueeze(0)- c*torch.diag(self.step_size[k]).unsqueeze(0)@(torch.eye(num_of_nodes).unsqueeze(0)- W)\n",
    "            #print(W_hat)\n",
    "            temp = 2*x_1-x_0 - torch.diag(self.step_size[k])@(self.tgrad_qp(A, b, x_1)-self.tgrad_qp(A, b, x_0))\n",
    "            conv_result = self.conv(temp,pyg_data)\n",
    "            x_32 = x_12 - x_1 + temp - c*torch.diag(self.step_size[k]).unsqueeze(0)@ (temp - conv_result)\n",
    "            #x_32 = x_12-x_1 + self.conv(temp,pyg_data)\n",
    "            #x_32 =x_12 - x_1 + w@temp\n",
    "            x_2 = self.act(x_32, k)\n",
    "            \n",
    "            ret_z.append(x_2)\n",
    "\n",
    "            x_0 = x_1\n",
    "            x_1 = x_2\n",
    "            x_12 = x_32\n",
    "            \n",
    "\n",
    "            k = k + 1\n",
    "            x_hist.append(x_2)\n",
    "        \n",
    "        ret_z = torch.stack(ret_z)\n",
    "        return ret_z, x_2,x_hist\n",
    "model_NIDS = Net_NIDS(1e-3, num_layers,num_nodes)\n",
    "optimizer = optim.Adam(model_NIDS.parameters(), lr=1e-4)\n",
    "model_NIDS.train()\n",
    "epoch_losses = []\n",
    "for epoch in range(500):\n",
    "    epoch_loss = 0\n",
    "    for iter, (W, A, y, x_true,pyg_data) in enumerate(train_loader):\n",
    "        z, _,_ = model_NIDS(W, A, y, pyg_data,num_layers)\n",
    "        loss = step_loss(0.83,z, x_true)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch_loss, model_NIDS.lam[1], model_NIDS.step_size[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Origin Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tgrad_qp(A, b, x):\n",
    "    # A: nodes * k * n\n",
    "    # X: nodes * n\n",
    "    # Y: nodes * k\n",
    "    '''grad_A = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        grad_A[i] = A[i].T @ (A[i] @ x[i] - b[i])\n",
    "    return grad_A'''\n",
    "    x_ = torch.unsqueeze(x, axis = -1)\n",
    "    b_ = torch.unsqueeze(b, axis = -1)\n",
    "    \n",
    "    A_t = A.transpose(2,3)\n",
    "    grad_A = A_t @ (A @ x_ - b_)\n",
    "    # print(A.shape, x.shape, b.shape)\n",
    "    grad_A = torch.squeeze(grad_A, axis = -1)\n",
    "    return grad_A\n",
    "\n",
    "def torch_soft(x, tau):\n",
    "    return F.relu(x - tau) - F.relu( - x - tau)\n",
    "\n",
    "def opt_distance(x,opt):\n",
    "    error = 0\n",
    "    batch_size = x.shape[0]\n",
    "    num_of_nodes = x.shape[1]\n",
    "    error = np.linalg.norm(x-opt)**2\n",
    "    return error/num_of_nodes/batch_size\n",
    "\n",
    "def hist_nmse(x_hist,opt):\n",
    "    error = []\n",
    "    iteration = len(x_hist)\n",
    "    #print(iteration)\n",
    "    for k in range(iteration):\n",
    "        error.append(10*np.log10(opt_distance(x_hist[k].detach(),opt)))\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin PG-EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.01 \t 0.6121812090940075 \t 0.4883340015353042\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.05 \t 0.6109607461113482 \t 0.48309061967754857\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.1 \t 0.6095678030011478 \t 0.476906510771225\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.5 \t 0.6035927633545652 \t 0.44243416698818505\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 1 \t 0.6067563873250037 \t 0.42840827966261896\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 5 \t 0.7973034541161106 \t 0.6869779006914469\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.01 \t 0.5497892530757891 \t 0.43603226793956124\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.05 \t 0.5470555619019506 \t 0.4275494741711755\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.1 \t 0.5438668566773486 \t 0.41755433304936745\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.5 \t 0.5268345618986132 \t 0.3627158631314542\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 1 \t 0.522902399115992 \t 0.33923231854573715\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 5 \t 0.7453494304011765 \t 0.6332978530419059\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.01 \t 0.48819077434077185 \t 0.38729155274260124\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.05 \t 0.483076687335968 \t 0.3740432388660338\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.1 \t 0.477053257638363 \t 0.3585969371217725\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.5 \t 0.4433072752229127 \t 0.27884910629515797\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 1 \t 0.4295285306534807 \t 0.24852751830549097\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 5 \t 0.6867067241000768 \t 0.5843936214451678\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.01 \t 0.38736332571024107 \t 0.31118993067468\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.05 \t 0.3743831398082257 \t 0.2828414242011495\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.1 \t 0.35927135276622907 \t 0.2515928017287097\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.5 \t 0.280540063211236 \t 0.12865522480315303\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 1 \t 0.25005582813723776 \t 0.11077101216517303\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 5 \t 0.5841959289071383 \t 0.5283634359483331\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.01 \t 0.29168512966731397 \t 0.2391167252694213\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.05 \t 0.25697513202019034 \t 0.17209783619524568\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.1 \t 0.219897794468141 \t 0.11299406772177463\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.5 \t 0.09149424355124619 \t 0.023685234617187686\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 1 \t 0.08440953293198664 \t 0.0495090958652163\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 5 \t 0.5208712276286751 \t 0.5144244942851656\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.01 \t 2.7772362438594522e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.05 \t 2.5884555069752845e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.1 \t 2.363942851178131e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.5 \t 1.0450044482654898e+23 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 1 \t 2.806476899569432e+22 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 5 \t 0.5145184702836267 \t 0.5142058619987874\n"
     ]
    }
   ],
   "source": [
    "def torch_PGEXTRA(W, A, b, max_iter, step_size,tau):\n",
    "    (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "    init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "    \n",
    "    \n",
    "    (batch_size, num_of_nodes, dim) = init_x.shape\n",
    "    I = torch.unsqueeze(torch.eye(num_of_nodes), axis = 0)\n",
    "    I = I.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    W_hat = (W + I)/2\n",
    "    \n",
    "    #initialization\n",
    "    k = 1\n",
    "    x_0 = init_x\n",
    "    x_12 = W @ x_0 - step_size * tgrad_qp(A, b, x_0)\n",
    "    x_1 = torch_soft(x_12, tau*step_size)\n",
    "    \n",
    "    x_hist = [init_x,x_1] #add for plot\n",
    "    while (k < max_iter):\n",
    "        \n",
    "        x_32 = W@x_1 + x_12 - W_hat@x_0 - \\\n",
    "            step_size*(tgrad_qp(A, b, x_1)-tgrad_qp(A, b, x_0))\n",
    "        x_2 = torch_soft(x_32, tau*step_size)\n",
    "        \n",
    "        x_0 = x_1\n",
    "        x_1 = x_2\n",
    "        x_12 = x_32\n",
    "        \n",
    "        k = k + 1\n",
    "        \n",
    "        x_hist.append(x_2)\n",
    "        \n",
    "    return x_2,x_hist\n",
    "\n",
    "lams = [5e-4,7e-4,1e-3, 2e-3,5e-3,1e-2]\n",
    "taus = [1e-2, 5e-2,1e-1,5e-1, 1, 5]\n",
    "best_error = 100\n",
    "best_par = {}\n",
    "for lam in lams:\n",
    "    for tau in taus:\n",
    "        for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "            original,origin_hist = torch_PGEXTRA(W, A, y, 100, lam, tau)\n",
    "            loss2 = opt_distance(original.detach().numpy(), x_true.numpy())\n",
    "            loss1 = opt_distance(origin_hist[num_layers].detach().numpy(),x_true.numpy())\n",
    "            \n",
    "            print(\"lamb\\ttau\\tlayer_loss\\t\\tfinal_loss\")\n",
    "            print(lam,'\\t', tau, '\\t',loss1,'\\t',loss2)\n",
    "            \n",
    "            if loss2 < best_error:\n",
    "                best_par['lam'] = lam\n",
    "                best_par['tau'] = tau\n",
    "                best_error = loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lam': 0.005, 'tau': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(best_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin DGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.01 \t 0.6282407981586876 \t 0.502789480182175\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.05 \t 0.6272877297943996 \t 0.49794653698162433\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.1 \t 0.6262156332784871 \t 0.4922667078634568\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 0.5 \t 0.6221691908236899 \t 0.460967667287332\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 1 \t 0.6267444088241974 \t 0.4494386707955145\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0005 \t 5 \t 0.8041094202755558 \t 0.6969039375269859\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.01 \t 0.5711177319337439 \t 0.4538151008090226\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.05 \t 0.5688216942610524 \t 0.4458950246293098\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.1 \t 0.5661529576795946 \t 0.4366282253426489\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 0.5 \t 0.5524852481475391 \t 0.3862438521709119\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 1 \t 0.551204882723694 \t 0.36606067848042767\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.0007 \t 5 \t 0.7564790800229021 \t 0.6470133915718834\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.01 \t 0.5155653896161312 \t 0.40892600802291595\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.05 \t 0.5111147628530235 \t 0.3964418256618974\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.1 \t 0.5059080004416247 \t 0.3820036568061987\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 0.5 \t 0.4775475676337446 \t 0.3080030319370053\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 1 \t 0.4681148203839548 \t 0.28141130459263697\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.001 \t 5 \t 0.7037066231439895 \t 0.6021947462488897\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.01 \t 0.42774387155171284 \t 0.3410246005471872\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.05 \t 0.41601259130775176 \t 0.3139733473578308\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.1 \t 0.4024888103732447 \t 0.2843390251432738\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 0.5 \t 0.33355759746940933 \t 0.16687443562132104\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 1 \t 0.3099347048749787 \t 0.1497595417538996\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.002 \t 5 \t 0.6140665903422341 \t 0.5537692570758809\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.01 \t 0.3506792358823077 \t 0.279646219951399\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.05 \t 0.3182124388694065 \t 0.2148550928708737\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.1 \t 0.28375789415877806 \t 0.1568216284365626\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 0.5 \t 0.16290609056253924 \t 0.054220737654596174\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 1 \t 0.1564879335265432 \t 0.0840162268982208\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.005 \t 5 \t 0.5651317725051486 \t 0.5550998774808322\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.01 \t 5.5192812765785205e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.05 \t 5.197617717212556e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.1 \t 4.811994516846711e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 0.5 \t 2.454035114205908e+26 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 1 \t 8.458446330993355e+25 \t inf\n",
      "lamb\ttau\tlayer_loss\t\tfinal_loss\n",
      "0.01 \t 5 \t 0.5737927032052831 \t 0.5730847588472825\n"
     ]
    }
   ],
   "source": [
    "def torch_DGD(W, A, b, max_iter, step_size,tau):\n",
    "    (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "    init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "    \n",
    "    \n",
    "    (batch_size, num_of_nodes, dim) = init_x.shape\n",
    "    I = torch.unsqueeze(torch.eye(num_of_nodes), axis = 0)\n",
    "    I = I.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    W_hat = (W + I)/2\n",
    "    \n",
    "    #initialization\n",
    "    k = 1\n",
    "    x_0 = init_x\n",
    "    x_12 = W @ x_0 - step_size * tgrad_qp(A, b, x_0)\n",
    "    x_1 = torch_soft(x_12, tau*step_size)\n",
    "    \n",
    "    x_hist = [init_x,x_1] #add for plot\n",
    "    while (k < max_iter):\n",
    "        \n",
    "        x_32 = W@x_1 -  step_size*tgrad_qp(A, b, x_1)\n",
    "        x_2 = torch_soft(x_32, tau * step_size)\n",
    "        \n",
    "        x_0 = x_1\n",
    "        x_1 = x_2\n",
    "        x_12 = x_32\n",
    "        \n",
    "        k = k + 1\n",
    "        \n",
    "        x_hist.append(x_2)\n",
    "        \n",
    "    return x_2,x_hist\n",
    "lams = [5e-4,7e-4,1e-3, 2e-3,5e-3,1e-2]\n",
    "taus = [1e-2, 5e-2,1e-1,5e-1, 1, 5]\n",
    "best_error = 100\n",
    "best_par = {}\n",
    "for lam in lams:\n",
    "    for tau in taus:\n",
    "        for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "            original,origin_hist = torch_DGD(W, A, y, 100, lam, tau)\n",
    "            loss2 = opt_distance(original.detach().numpy(), x_true.numpy())\n",
    "            loss1 = opt_distance(origin_hist[num_layers].detach().numpy(),x_true.numpy())\n",
    "            \n",
    "            print(\"lamb\\ttau\\tlayer_loss\\t\\tfinal_loss\")\n",
    "            print(lam,'\\t', tau, '\\t',loss1,'\\t',loss2)\n",
    "            if loss2 < best_error:\n",
    "                best_par['lam'] = lam\n",
    "                best_par['tau'] = tau\n",
    "                best_error = loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lam': 0.005, 'tau': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(best_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin NIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef torch_NIDS(W, A, b, max_iter, step_size,tau):\\n    (batch_size, num_of_nodes, _, dim) = A.shape\\n    init_x = torch.zeros((batch_size, num_of_nodes, dim))\\n    c = 1/(2*step_size)\\n    \\n    (batch_size, num_of_nodes, dim) = init_x.shape\\n    I = torch.unsqueeze(torch.eye(num_of_nodes), axis = 0)\\n    I = I.repeat(batch_size, 1, 1)\\n    \\n    \\n    #initialization\\n    k = 1\\n    x_0 = init_x\\n    #print(alpha.unsqueeze(-1).shape)\\n    x_12 = x_0 -step_size* tgrad_qp(A, b, x_0)\\n    x_1 = torch_soft(x_12, tau*step_size)\\n    \\n    x_hist = [init_x,x_1] #add for plot\\n    while (k < max_iter):\\n        W_hat = torch.eye(num_of_nodes).unsqueeze(0)- c*step_size*(torch.eye(num_of_nodes).unsqueeze(0)- W)\\n        x_32 = x_12-x_1 + W_hat@(2*x_1-x_0 - step_size*(tgrad_qp(A, b, x_1)-tgrad_qp(A, b, x_0)))\\n        x_2 = torch_soft(x_32, tau*step_size)\\n        \\n        x_0 = x_1\\n        x_1 = x_2\\n        x_12 = x_32\\n        \\n        k = k + 1\\n        \\n        x_hist.append(x_2)\\n        \\n    return x_2,x_hist\\nlams = [5e-4,1e-3, 5e-3,1e-2]\\ntaus = [1e-2, 5e-1, 1, 5]\\nbest_error = 100\\nbest_par = {}\\n#cs = [ 5e-1, 1,10,20,50,200]\\nfor lam in lams:\\n    for tau in taus:\\n        for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\\n            original,origin_hist = torch_NIDS(W, A, y, 100, lam, tau)\\n            loss2 = opt_distance(original.detach().numpy(), x_true.numpy())\\n            loss1 = opt_distance(origin_hist[num_layers].detach().numpy(),x_true.numpy())\\n            \\n            print(\"lamb\\t tau\\t c\\t layer_loss\\t\\t final_loss\")\\n            print(lam,\\'\\t\\', tau, \\'\\t\\',1/(2*lam),\\'\\t\\',loss1,\\'\\t\\',loss2)\\n            if loss2 < best_error:\\n                best_par[\\'lam\\'] = lam\\n                best_par[\\'tau\\'] = tau\\n                best_par[\\'c\\'] = 1/(2*lam)\\n                best_error = loss2\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def torch_NIDS(W, A, b, max_iter, step_size,tau):\n",
    "    (batch_size, num_of_nodes, _, dim) = A.shape\n",
    "    init_x = torch.zeros((batch_size, num_of_nodes, dim))\n",
    "    c = 1/(2*step_size)\n",
    "    \n",
    "    (batch_size, num_of_nodes, dim) = init_x.shape\n",
    "    I = torch.unsqueeze(torch.eye(num_of_nodes), axis = 0)\n",
    "    I = I.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    \n",
    "    #initialization\n",
    "    k = 1\n",
    "    x_0 = init_x\n",
    "    #print(alpha.unsqueeze(-1).shape)\n",
    "    x_12 = x_0 -step_size* tgrad_qp(A, b, x_0)\n",
    "    x_1 = torch_soft(x_12, tau*step_size)\n",
    "    \n",
    "    x_hist = [init_x,x_1] #add for plot\n",
    "    while (k < max_iter):\n",
    "        W_hat = torch.eye(num_of_nodes).unsqueeze(0)- c*step_size*(torch.eye(num_of_nodes).unsqueeze(0)- W)\n",
    "        x_32 = x_12-x_1 + W_hat@(2*x_1-x_0 - step_size*(tgrad_qp(A, b, x_1)-tgrad_qp(A, b, x_0)))\n",
    "        x_2 = torch_soft(x_32, tau*step_size)\n",
    "        \n",
    "        x_0 = x_1\n",
    "        x_1 = x_2\n",
    "        x_12 = x_32\n",
    "        \n",
    "        k = k + 1\n",
    "        \n",
    "        x_hist.append(x_2)\n",
    "        \n",
    "    return x_2,x_hist\n",
    "lams = [5e-4,1e-3, 5e-3,1e-2]\n",
    "taus = [1e-2, 5e-1, 1, 5]\n",
    "best_error = 100\n",
    "best_par = {}\n",
    "#cs = [ 5e-1, 1,10,20,50,200]\n",
    "for lam in lams:\n",
    "    for tau in taus:\n",
    "        for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "            original,origin_hist = torch_NIDS(W, A, y, 100, lam, tau)\n",
    "            loss2 = opt_distance(original.detach().numpy(), x_true.numpy())\n",
    "            loss1 = opt_distance(origin_hist[num_layers].detach().numpy(),x_true.numpy())\n",
    "            \n",
    "            print(\"lamb\\t tau\\t c\\t layer_loss\\t\\t final_loss\")\n",
    "            print(lam,'\\t', tau, '\\t',1/(2*lam),'\\t',loss1,'\\t',loss2)\n",
    "            if loss2 < best_error:\n",
    "                best_par['lam'] = lam\n",
    "                best_par['tau'] = tau\n",
    "                best_par['c'] = 1/(2*lam)\n",
    "                best_error = loss2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lam': 0.005, 'tau': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(best_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data = SynDataset(test_num)\n",
    "val_loader = DataLoader(val_data, batch_size=100, shuffle=False, collate_fn=collate)\n",
    "for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "    _,pred_PGEXTRA,pred_PGEXTRA_hist = model_PGEXTRA(W, A, y, pyg_data,num_layers)\n",
    "    _,pred_DGD,pred_DGD_hist = model_DGD(W, A, y, pyg_data,num_layers)\n",
    "    #_,pred_NIDS,pred_NIDS_hist = model_NIDS(W, A, y, pyg_data,num_layers)\n",
    "    \n",
    "    original_PGEXTRA,original_PGEXTRA_hist = torch_PGEXTRA(W, A, y, 500,0.005,0.5)\n",
    "    original_DGD, original_DGD_hist = torch_DGD(W, A, y, 500,0.005,0.5)\n",
    "    #original_NIDS, original_NIDS_hist = torch_NIDS(W, A, y, 200,0.005,0.01)\n",
    "\n",
    "\n",
    "origin_PGEXTRA_error = hist_nmse(original_PGEXTRA_hist,x_true)\n",
    "origin_DGD_error = hist_nmse(original_DGD_hist,x_true)\n",
    "#origin_NIDS_error = hist_nmse(original_NIDS_hist,x_true)\n",
    "pred_PGEXTRA_error = hist_nmse(pred_PGEXTRA_hist,x_true)\n",
    "pred_DGD_error = hist_nmse(pred_DGD_hist,x_true)\n",
    "#pred_NIDS_error = hist_nmse(pred_NIDS_hist,x_true)\n",
    "\n",
    "long_end = 200\n",
    "x_long = [i for i in range(long_end+1)]\n",
    "plt.plot(x_long,origin_DGD_error[:long_end+1],linewidth=2,linestyle='--',color = 'tab:red')\n",
    "plt.plot(x_long,origin_PGEXTRA_error[:long_end+1],linewidth=2,linestyle='--',color = 'tab:blue' )\n",
    "#plt.plot(x_long,origin_NIDS_error[:long_end+1],linewidth=3)\n",
    "\n",
    "x = [i for i in range(num_layers+1)]\n",
    "plt.plot(x,pred_DGD_error[:num_layers+1],linewidth=2,color = 'tab:red')\n",
    "plt.plot(x,pred_PGEXTRA_error[:num_layers+1],linewidth=2,color = 'tab:blue')\n",
    "#plt.plot(x,pred_NIDS_error[:num_layers+1],linewidth=3)\n",
    "\n",
    "plt.legend(['Prox-DGD','PG-EXTRA','GNN-Prox-DGD','GNN-PG-EXTRA'],loc='upper right',fontsize='large') \n",
    "plt.xlabel('iterations',fontsize= 'x-large')\n",
    "plt.ylabel('NMSE',fontsize= 'x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\\n    _,pred_PGEXTRA,pred_PGEXTRA_hist = model_PGEXTRA(W, A, y, pyg_data,num_layers)\\n    _,pred_DGD,pred_DGD_hist = model_DGD(W, A, y, pyg_data,num_layers)\\n    \\n    original_PGEXTRA,original_PGEXTRA_hist = torch_PGEXTRA(W, A, y, num_layers,0.002 \\t 2 )\\n    original_DGD, original_DGD_hist = torch_DGD(W, A, y, num_layers,0.001,0.05)\\n    original_NIDS, original_NIDS_hist = torch_NIDS(W, A, y, num_layers,0.005,0.5 ,7 )\\n\\n\\norigin_PGEXTRA_error = hist_nmse(original_PGEXTRA_hist,x_true)\\norigin_DGD_error = hist_nmse(original_DGD_hist,x_true)\\norigin_NIDS_error = hist_nmse(original_NIDS_hist,x_true)\\npred_PGEXTRA_error = hist_nmse(pred_PGEXTRA_hist,x_true)\\npred_DGD_error = hist_nmse(pred_DGD_hist,x_true)\\n\\n#plt.rc('text',usetex=True)nn\\n\\nx = [i for i in range(num_layers+1)]\\nplt.plot(x,origin_DGD_error[:num_layers+1])\\nplt.plot(x,origin_PGEXTRA_error[:num_layers+1])\\nplt.plot(x,origin_NIDS_error[:num_layers+1])\\n\\nplt.plot(x,pred_DGD_error[:num_layers+1])\\nplt.plot(x,pred_PGEXTRA_error[:num_layers+1])\\n\\n\\nplt.legend(['Prox-DGD','PG-EXTRA','NIDS','GNN-Prox-DGD','GNN-PG-EXTRA'],loc='upper right',fontsize='x-large') \\nplt.xlabel('iterations',fontsize= 'x-large')\\nplt.ylabel('NMSE',fontsize= 'x-large')\\n\\nplt.show()\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for iter, (W, A, y, x_true,pyg_data) in enumerate(val_loader):\n",
    "    _,pred_PGEXTRA,pred_PGEXTRA_hist = model_PGEXTRA(W, A, y, pyg_data,num_layers)\n",
    "    _,pred_DGD,pred_DGD_hist = model_DGD(W, A, y, pyg_data,num_layers)\n",
    "    \n",
    "    original_PGEXTRA,original_PGEXTRA_hist = torch_PGEXTRA(W, A, y, num_layers,0.002 \t 2 )\n",
    "    original_DGD, original_DGD_hist = torch_DGD(W, A, y, num_layers,0.001,0.05)\n",
    "    original_NIDS, original_NIDS_hist = torch_NIDS(W, A, y, num_layers,0.005,0.5 ,7 )\n",
    "\n",
    "\n",
    "origin_PGEXTRA_error = hist_nmse(original_PGEXTRA_hist,x_true)\n",
    "origin_DGD_error = hist_nmse(original_DGD_hist,x_true)\n",
    "origin_NIDS_error = hist_nmse(original_NIDS_hist,x_true)\n",
    "pred_PGEXTRA_error = hist_nmse(pred_PGEXTRA_hist,x_true)\n",
    "pred_DGD_error = hist_nmse(pred_DGD_hist,x_true)\n",
    "\n",
    "#plt.rc('text',usetex=True)nn\n",
    "\n",
    "x = [i for i in range(num_layers+1)]\n",
    "plt.plot(x,origin_DGD_error[:num_layers+1])\n",
    "plt.plot(x,origin_PGEXTRA_error[:num_layers+1])\n",
    "plt.plot(x,origin_NIDS_error[:num_layers+1])\n",
    "\n",
    "plt.plot(x,pred_DGD_error[:num_layers+1])\n",
    "plt.plot(x,pred_PGEXTRA_error[:num_layers+1])\n",
    "\n",
    "\n",
    "plt.legend(['Prox-DGD','PG-EXTRA','NIDS','GNN-Prox-DGD','GNN-PG-EXTRA'],loc='upper right',fontsize='x-large') \n",
    "plt.xlabel('iterations',fontsize= 'x-large')\n",
    "plt.ylabel('NMSE',fontsize= 'x-large')\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = SynDataset(test_num)\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False, collate_fn=collate)\n",
    "for iter, (W, A, y, x_true,pyg_data) in enumerate(test_loader):\n",
    "    _,pred_PGEXTRA,pred_PGEXTRA_hist = model_PGEXTRA(W, A, y, pyg_data,num_layers)\n",
    "    _,pred_DGD,pred_DGD_hist = model_DGD(W, A, y, pyg_data,num_layers)\n",
    "    #_,pred_NIDS,pred_NIDS_hist = model_NIDS(W, A, y, pyg_data,num_layers)\n",
    "    \n",
    "    original_PGEXTRA,original_PGEXTRA_hist = torch_PGEXTRA(W, A, y, 500,0.005,0.5)\n",
    "    original_DGD, original_DGD_hist = torch_DGD(W, A, y, 500,0.005,0.5)\n",
    "    #original_NIDS, original_NIDS_hist = torch_NIDS(W, A, y, 200,0.005,0.01)\n",
    "\n",
    "\n",
    "origin_PGEXTRA_error = hist_nmse(original_PGEXTRA_hist,x_true)\n",
    "origin_DGD_error = hist_nmse(original_DGD_hist,x_true)\n",
    "#origin_NIDS_error = hist_nmse(original_NIDS_hist,x_true)\n",
    "pred_PGEXTRA_error = hist_nmse(pred_PGEXTRA_hist,x_true)\n",
    "pred_DGD_error = hist_nmse(pred_DGD_hist,x_true)\n",
    "#pred_NIDS_error = hist_nmse(pred_NIDS_hist,x_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"D\"+str(n)+\"M\"+str(m)+\"NO\"+str(nnz)\n",
    "writer_error=pd.ExcelWriter(\"./error_fig/noise1/\"+figure_name+\".xls\")\n",
    "df_error= pd.DataFrame({'PG-EXTRA':origin_PGEXTRA_error,'DGD':origin_DGD_error})\n",
    "df_error.to_excel(writer_error,sheet_name='Origin')\n",
    "    \n",
    "df_feasibility= pd.DataFrame({'PG-EXTRA':pred_PGEXTRA_error,'DGD':pred_DGD_error})\n",
    "df_feasibility.to_excel(writer_error,sheet_name='GNN')\n",
    "writer_error.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEOCAYAAACetPCkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd0FNXbwPHv3ZbeKykkgdCrgChNUERQmoB0aRZAQFT42UAp6iuCooIKKKJUAQWkF0UQUCkCAtIhCWmQTnrPzvvHkiUJ6aRs4v2cs8fMzsyduxF49tZHKIqCJEmSJJWWqrorIEmSJNUsMnBIkiRJZSIDhyRJklQmMnBIkiRJZSIDhyRJklQmMnBIkiRJZSIDhyRJklQmMnBIkiRJZSIDhyRJklQmmuquQGVwdnZWfH19q7sakiRJNcqpU6diFEVxKem6Whk4fH19OXnyZHVXQ5IkqUYRQgSX5jrZVSVJkiSViQwckiRJUpnIwCFJkiSViQwckiRJUpnUysFxSZIMEhMTiYqKIisrq7qrIpkIKysrvLy8UKnK326QgUOSaqnExEQiIyPx9PTEwsICIUR1V0mqZnq9nvDwcGJiYnB1dS13ObKrSpJqqaioKDw9PbG0tJRBQwJApVLh5uZGQkLC/ZVTQfWpVeJWryZq4afVXQ1Jui9ZWVlYWFhUdzUkE6PVasnOzr6vMmTgKET054uIXb6cnPuMypJU3WRLQyqoIv5MyMBRgJKVhT41FQB9Wlo110aSJMn0yMBRQE5ysvFnGTgkqfL4+vpiYWGBtbU1bm5ujB07luQ8f/8qixACKysrrK2tcXJyonv37mzcuPGe63799VceffRRbGxscHJyonXr1syfP5/09HQA5syZg1arxcbGBhsbGxo2bMiUKVO4detWpX+G6iYDRwH6PH9wlYyMaqyJJNV+O3bsIDk5mdOnT3Py5Ek++OCDfOcVRUGv11f4c8+ePUtycjJXrlxh7NixTJkyhblz5xrP//TTTzzzzDOMGDGC4OBgYmNj2bhxI2FhYYSGhhqvGzp0KElJScTFxfHzzz8TERFB27Zta33wkIGjgJzEROPPssUhSVXD09OTJ598kvPnz9OtWzdmzpxJp06dsLS0JDAwkJs3b9KvXz8cHR3x9/dn+fLlxnufeuoppk+fbjweNmwYzz33XKme6+zszKhRo1i6dCnz5s0jNjYWRVGYNm0as2bN4sUXX8TR0RGARo0a8cUXX9CgQYN7ytFqtTRr1oyNGzfi4uLCwoUL7/M3YtrkOo4C9EmyxSFJVS00NJTdu3czcOBAjhw5wpo1a9izZw+NGjVCURS6d+9O8+bNuXnzJpcvX6ZHjx7Ur1+fxx57jO+++46WLVvSu3dvbt26xYkTJzh79myZnt+/f3+ys7M5ceIEfn5+hIWFMWjQoDJ/DrVaTf/+/dm3b1+Z761JZOAoQJ+cdPdn2eKQaplLjZsUec597lwchg4B4PbGH4mYPbvIa5tcvmT8OWjgINIvXrzn/dJ4+umn0Wg02NnZ0bt3b2bMmMGTTz7J2LFjadasGWAIKn/++Se7du3C3Nyc1q1b88ILL7B69Woee+wx3N3dWbp0KWPGjCEtLY2tW7diY2NTpnpotVqcnZ2Ji4sz3uvu7m48P2zYMPbu3UtmZiZff/01o0aNKrIsDw8P4uLiyvT8mkZ2VRWQk7fFcWcQTJKkyrF161bi4+MJDg5myZIlxnUn3t7exmtu3ryJo6NjvmDg4+NDeHi48bhv377k5OTQqFEjOnfubHy/WbNmWFtbY21tzZEjR4qsR1ZWFtHR0Tg6OuLk5ASQb5xiw4YNxMfH06ZNG3Jycor9TOHh4cburdpKtjgK0CflGeNIl11VUu1S2haBw9AhxtZHSfy2bL6fKhUq71qD3G/wSUlJxuAREhKCp6en8ZqZM2fSpEkTgoKCWL9+PcOHDwfgwoULpXretm3b0Gg0tG/fHgcHBzw9PdmyZUu+sZPS0Ov17Nixg8cff7xM99U0ssVRQE7S3a4qJV12VUlSdfP29qZjx468/fbbpKenc+7cOVasWMGzzz4LwOHDh/n+++9ZvXo1q1at4uWXX87XGilOXFwc69atY/Lkybz55ps4OTmhUqlYuHAhc+fOZfny5dy+fRtFUbh27RqRkZGFlpOdnc2lS5cYPnw4ERERTJs2rcI+vymSLY4C8g6OyxaHJJmG9evXM3HiRDw8PHBwcGDu3Lk8/vjjJCYmMnr0aL788ks8PT3x9PTk+eefZ9y4cezbt6/IVdKtWrVCCIFOp6NVq1Z89tlnjBgxwnh+6NCh2NnZMW/ePF577TXMzMyoW7cu48ePZ/DgwcbrNm7cyNatW1EUBQ8PD3r06MGpU6fw8PCo9N9JdRKKolR3HSpcu3btlPLmHL/5zjskbDI0vV1emYrzSy9VZNUkqcpcunSJJk2KHgyX/ruK+rMhhDilKEq7ku6XXVUF6BPzzqqSg+OSJEkFycBRQN7puEqGDBySJEkFycBRQN7puLLFIUmSdC8ZOArQJ8kWhyRJUnFk4Cgg73Rc2eKQJEm6lwwcBeRtcejlOg5JkqR7yMCRhz4zEyUz03isyHUckiRJ95CBI4+8rQ0AvdyrSpIk6R4ycOSRNxcHyE0OJUmSCiMDRx652f9UVlaGYxk4JKnSFJc6tqS0rQXduHEDIYRxJ9zcV25K2EGDBvHiiy/mu2fAgAFMmTKFDz/80Hi9ubk5arXaeJy7tXvedLOenp5Mmzat0F1yx44di0ajkRkATYUQopcQ4ooQ4roQ4q3KeEZuV5XGxQUARebjkKRKVVjq2NKmbS1MfHw8ycnJxtfQoUMB+Oqrr9iyZQsHDx4EDHtMnT59mo8++ogZM2YYr1+2bBkdOnQwHufdXTc33eyhQ4fYuHEj3333Xb5np6SksHnzZuzs7Fi7dm0F/6ZMS40IHEIINfAV8CTQFBguhGha0c/JXfyXGzj0MgOgJFWJ3NSx//77b5nTtpaGu7s7Cxcu5MUXXyQkJISpU6fy9ddfY21tXeay/P396dSpE2fOnMn3/ubNm7G3t2fWrFmsWrWqXPWsKWpE4ADaA9cVRQlUFCUT2AD0r+iHZCclccmhLnEuXoBscUhSVclNHWtpaVnutK0lGTt2LPXr16dNmzb06tWLXr16laucy5cvc+TIEfz9/fO9v2rVKoYPH86wYcO4fPkyp06dqohqm6Sasq26J5C3jRoGPFTRD/kkQM8PXacyJPkK44RAycpCyclBqNUV/ShJqha+b+0q8tyHA1ow4qG6APxwPIQZP/9b5LU3Pupt/LnPF0c4H554z/ulUTB17PDhw9m0aVO507Y6OzvnOz569Gi+XWC7dOnCL7/8YszlURa52f9SU1MZNmwYkyZNMp4LCQnh4MGDLFy4EDc3N7p3787q1atp27ZtmZ9TE9SUFkeJhBDjhRAnhRAno6Ojy1WGb2osAPs1dRDm5oCcWSVJlalg6tjcf/hLStuadwA8JCTEeG1MTAzx8fHGV96gce3aNT755BMmTZrE9OnTycrKKlNdT58+TXJyMhs3buT48eOkpKQYz61Zs4YmTZrQunVrAEaOHMkPP/xQ5mfUFDWlxREOeOc59rrznpGiKN8A34AhH0d5HvLsW88xb84vxJnbctPCgTppaejT042zrCSppitti2DEQ3WNrY+S7Hy5y/1UKZ9GjRqVKm1r7uyrXDdu3Ci2XEVReOGFF3j11VeZNWsWnTp1Yv78+bzzzjtlqp8QgiFDhrBt2zbee+89Pv/8cwBWr15NSEiIsaWUnZ1NbGwsu3fvpn//Cu9Vr3Y1pcXxN9BACOEnhNABw4DtFf0QSwsd9XTZABx2bgzIFockVaXypG0tjaVLlxITE8OMGTNQqVSsWLGCBQsWcPny5XKV99Zbb7F8+XIiIiI4evQoAQEBnDhxgjNnznDmzBnOnz/PiBEjWL16dbnrbMpqROBQFCUbmALsAy4BPyqKUros9GX07COGAa/jboZJW3IthyRVraFDh/Ljjz+ydu1avL29cXZ2ZsiQIfekbS2Mvb19vm6sTz/9lJCQEGbMmMGKFSvQ6XQANG3alOnTp/Piiy9SniyoLVq04JFHHuHjjz9m1apV9O/fnxYtWuDu7m58vfLKK+zcuZO4uLhy/R5MmUwdW0B8aiYPvPcLQq+w+pcPaLN2BZbNm1dwDSWp8snUsVJRZOrYCmZvqeMxf0f0KhXb6nXm1y2/V3eVJEmSTIoMHIWY8oQhEu/y60Dj5n7VXBtJkiTTIgNHIR6o60Dr7FhStRbsj68pE88kSZKqhgwcReinGOaRn4zJJj05hcDd+6u5RpIkSaZBfp0uQkOtIaHTpcQcnnh3K9bJt9lgocb20UeruWaSJEnVS7Y4iuBjrqDJySYiW02SuQ0XnfxY/ekPZJaw0EiSJKm2k4GjCDoLc+omGxYcjezWEIDl/o9z6eVp9yR8kiRJ+i+RgaMIKgtz/BIM4xx17C1o521Hgpk131o0IvSlSejlzrmSJP1HycBRBGFmjm9iBABXIpJ4f2BL1AJ2+XXk3+sRhL82DaWWbmAmSZJUHBk4iqCyMMcv8SYAlyOSaFLHljEd/dALFUvaDEY4OoIQ1VxLSarZNmzYwEMPPYSVlRWurq489NBDLFmyBEVRGDt2LEIITpw4Ybz++vXriDx/77p164a5uXm+zID79+/H19e3yGfOmTMHrVaLtbU19vb2dOzYkaNHj1bK5yto7Nix6HQ6bGxssLGxoXnz5rz99tskJCTku+7WrVu8+OKLeHh4YG1tTb169Rg7dqxxb62CqXLd3Nzo06cPv/76a5V8Dhk4iqB2cjK2OC7fSkRRFF7t0YAmdWwZO6gjdd5/H6GRk9IkqbwWLlzIK6+8wuuvv05ERASRkZEsW7aMP//8k8xMw6xGR0fHEnewtbKy4v333y/Ts4cOHUpycjLR0dF07tyZgQMHFrpnVXZ2dpnKLY033niDpKQkoqOj+f777zl27BidOnUybtMeGxtLx44dSU1N5ciRIyQlJXH69Gm6du16T2DITZV79uxZevTowYABA1i5cmWF17kgGTiKYObnh2N6InbZaSSmZxMUk4KtuZbdUzsz9PEWqNWGX11OfDzRS5agFJK4XpKkwiUkJDBr1iyWLFnCM888g42NDUIIHnjgAdatW4eZmRkAY8aM4dy5cxw6dKjIsqZOncr69esJCAgocz20Wi1jxowhIiKC2NhYVq5cSadOnXjttddwcnJizpw56PV6PvjgA3x8fHB1dWX06NHGFsLGjRvx8/Mj8c6EmT179uDu7k5pcgKZm5vz4IMPsn37dmJjY/n+++8B+Oyzz7C1tWXNmjXUr18fIQT29vaMGzeOl19+udCycjdVnDNnDm+++SZ6vb7Mv4uykIGjCDofHwTQJtLQNNx3wTDDKm8z+XZKBmFTXiZm8RfcmjEDpRK+nUhSbXT06FEyMjJKzFVhaWnJjBkzmDlzZpHXeHp68uKLLzJ79uwy1yMjI4OVK1cad+EFOH78OPXq1SMyMpKZM2eycuVKVq5cycGDBwkMDCQ5OZkpU6YAhpZLx44dmTp1KrGxsTz//PN8++23uLi4lLoONjY29OjRgyNHjgCGrrYBAwagUpX9n+eBAwcSFRXFlStXynxvWci+liKorKzQuLrSOewMBz0fYM/5W7zUrb7x/FcHr/Plget8M3IiLhenkrBtOzlJyXh+uhDVneyBkmRKLjWump1ym1y+VOI1MTExODs7o8nT3duxY0cuXrxIRkYG+/btM74/YcIEPvnkE/bs2UODBg0KLe/tt9/G39+fCxdKl23hxx9/ZOfOneh0Opo3b87PP/9sPOfh4WH8Zq/RaFi3bh3Tpk2jXr16AMybN4/mzZvz/fffo9Fo+Oqrr2jZsiXdunWjb9++9OnTp1R1yMvDw8OYozwmJiZf6tzt27czevRocnJy6NChA7/88kux5QCVvpW7bHEUQ+fnR9vIK1io4VxYAmG3U43nUjKyScvKYea/mTgt/QaVnR3JBw4QMu45cuLjq7HWkmT6nJyciImJyTeG8NdffxEfH4+Tk1O+rhYzMzPeffdd3n333SLLc3FxYcqUKcyaNSvf++vWrTMOID/55JPG94cMGUJ8fDxRUVEcOHAgX25wb2/vfGXcvHkTHx8f47GPjw/Z2dnGxFL29vYMHjyY8+fP58ta+OGHHxqfPXHixGJ/H+Hh4Tg6Ohp/N3lT5/br14/4+Hg+++wz49hPceUAxrIqi2xxFEPn64vZ8eN0scrgl0Qz9vwbwYuPGL51vPp4Q36/Es3FW4ksDHNi7rq1hLzwImn//MONkc9Sd/k3aO9Ef0kyBaVpCVSVDh06YGZmxrZt2xg0aFCJ148bN4758+ezZcuWIq95/fXXqVevHu3btze+N3LkSEaOHFmmuokCsyU9PDwIDg42HoeEhKDRaHBzcwPgzJkzfPfddwwfPpypU6eyd+9eAGbMmMGMGTNKfF5ycjL79+83dsd1796drVu3Mnv27DJ3V/3888+4urrSqFGjMt1XVrLFUQydny8AndMNUfzPgJi75zQqPh/WGp1GxYa/QzmcaYPvhvWYNfAnMyCAhG3bqqHGklQz2NvbM3v2bCZNmsSmTZtISkpCr9dz5swZ4+yivDQaDXPnzmX+/PnFljl9+nQWLFhQoXUdPnw4n332GUFBQSQnJzNjxgyGDh2KRqMhPT2dZ599lg8//JDvv/+e8PBwlixZUqpyMzIyOHXqFE8//TQODg6MGzcOgGnTpnH79m1GjRpFQEAAiqKQlJTEmTNniiwrMjKSL7/8krlz5zJv3rxyjY+UhQwcxdDdmQve8KZhoOlcWEK+KXsN3Wx4s5chN/lbm89x29Ien7VrcZk2DacJE6q8vpJUk7zxxht8+umnLFiwADc3N9zc3JgwYQLz58+nY8eO91w/fPhw6tSpU2yZr7zyCmq1ukLr+dxzzzFq1CgeeeQR/Pz8MDc354svvgAMYyve3t689NJLmJmZsXbtWt555x2uXbtWZHkLFizAxsYGJycnRo8eTdu2bfnrr7+wsrICwNnZmWPHjmFubk7nzp2xsbGhdevWJCUlsXTp0nxl2dvbY2VlRYsWLdi9ezc//fQTzz33XIV+/sLI1LHFyLxxg4BeT6KuU4ehj77F7dQsjrzxKN6OlsZr9HqFUd8d58/rsfRo6sby0fmzLmZFRpL0634cRo64pwksSZVJpo6ViiJTx1YirZcXaDTk3LpFC3drAP4Nz7/CU6USfD70AR5v4srsvk3znVNycgh7eSqRH3zArbdnoC9hYEuSJKkmkIGjGEKjwaJ1KwD8Qy4CcDbs3hlTLjZmfDvmQbwcLPPfr1bj9NxzCHNzErZuJWT0GLKioiq/4pIkSZVIBo4SuL/zDmg0eP+xB4BzoQnFXq8oCl8fCuBsqCHA2Pbqie8P69DUqUPamTMEDRxESp69dyRJkmoaGThKYN64Mc4TJtDwtmETtX/DbnPjuedJ2l94Ktn1J0KZt+cyz686SWicYd2HedOm+P30I5bt25MTE0PI2HHErviuyj6DJElSRZKBoxScXnwBVzsLnFPjSc7Uc/F8EHGr1xR67TNtvejk70RMcgbjVv5NQqph63WNszN1v1uB0/jxoNcDtW9SgiRJ/w0ycJSCytwc55cm0ibaMC33mHtTMorYUE2nUbFkZFsaullzPSqZCWtPkpltWAUrNBpcp72G74b1OOaZMqfPyKj8DyFJklRBZOAoJftBg+icZdhi4KhHc3JiY8m+fbvQa+0stHw39kFcbMw4FhjHW5vP5Vv/YdG6tXFqblZ4OAFP9OT2hg2FbussSZJkamTgKCWh0zFg0RwsNIJr9t5Em9uRce0amWHh6NPT77ney8GS78c+iKVOzZZ/wlnxR1Ch5Sbu3Ut2ZCQRc+YS9vLLRQYjSZIkUyEDRxnYeNahS0NXAI7XaUbC5i0E9OxJ5IfzCr2+uacdXwx/gBaedvRv7VnoNU7PP4/Hwk9QWVuTvP83gp4eQMpxOetKkiTTJQNHGfVoatjY7Lh7U8N+VDk5pP1zusjruzdxY+vkTrjYmBV5jV3v3vht/RmLVq3IjowkZOxYohYtkvk9pFrPFFPHlpS2tTC59cjdDdfa2pq+ffsCsGPHDtzd3fNtdb5t2zY8PT0JDg7Od48QAisrK+PxkSNHjOlmra2tcXR0pEePHoXW5ffff0cIUex+XhVFBo4y6tbI0OI451yfDJVhc+HM0LBixyfUKsMfdL1eYd7uS/x+5d5FgDovL3zWrsHpJcP2y7HLvyXj+vWKrr4kmQxTTB1blrStBX355ZckJycbXzt27ACgb9++PPbYY7z22muAId3rSy+9xNKlS/Hx8cl3D8DZs2eNx126dAEM+3olJycTHh6Op6cnzz///D3PX7VqFY6OjqxevbpMv4vyMPnAIYSYI4QIF0KcufN6qjrr42JjRjMXCzLVWs47GbZYV9LTyS5Fqshd/97i68OBvLT2NKeC7x3LEFotrq+8Qt1VK3F/ZybmjRsbz8mBc6k2MdXUseVJ21oaixcvZs+ePezbt4/XXnuNrl270q9fvzKXY2FhwZAhQ+7ZKTclJYVNmzbx1Vdfce3aNSpir77imHzguOMzRVFa33ntru7KdG1myLNxyu3unvdZYWEl3tenZR0Gt/UiLSuH51b+zaVbiYVeZ9W+PQ7DhhmPE/f9QujEiXK7EqnWMNXUsfeTtrU4zs7OLFq0iJEjR7Jz504WL15crnJSUlJYv349/v7++d7fsmUL1tbWDB48mJ49e7Jq1aqKqHaRZCKncuja0IUlvwdwyq0xZtnXyLh8mcyQECzbtCn2PiEE8wa2ID4ti18vRjLy2+P88OJDNHa3LfIeJSeH6M8+I/PGDYL69sN9zmxs82Qyk6TS8n1rV5U858ZHvUu8xlRTx95P2tapU6fyv//9z3j88ssv5+tCe/jhh0lISGDIkCFlykkO8Mknn/Dll1+SmJiIj48P2wrk+1m1ahVDhw5FrVYzYsQIpk6dyqeffopWqy3Tc0qrprQ4pgghzgkhvhNCOFR3Zdr4OGCtUxNi40ZS5+4AZIWElnCXgUat4ovhD9CtkQtxKZmMWH6cyxGFtzzAsFFi3VUrsercmZyEBMJfm0b49P/J9LRSjWaqqWNLk7Z14sSJxjI//PBD47WLFy8mPj7e+Co47jJ+/HhGjx7N7t278w3Gl8b//vc/4uPjuXHjBhYWFly5csV4LjQ0lIMHDxozHfbv35/09HR27aq8Lwom0eIQQuwH3As5NRNYCryPYY+O94GFwD2ZSoQQ44HxAHXr1q20ugJo1So6+Dvz68VI/rH24iEgM6x0gQPAXKtm2bNtmbDmFIeuRvPBzkusfeGhop/n5ob38m+I37iRyPkLSNy1i9S//6bO/32A9Z3BM0kqSWlaAlXFVFPHliZt67Jly1i2bFmpywRYsWIFoaGh7Ny5k3bt2vHCCy/wzz//oNPpylRO3bp1WbRoEWPGjKFPnz5YWFiwZs0a9Hq9cRYXQHp6OqtWreLpp58uU/mlZRItDkVRHlcUpXkhr22KokQqipKjKIoeWA60L6KMbxRFaacoSruyNgPLo1N9JwD+zjHk6cgMDiZ+0yYyisn8lZe5Vs3Xo9ryXCc/vhj+QInXCyFwGDaMelt/xuKBB8iOiiLigw9QsrLK/yEkqZqYaurY8qRtLcnNmzd5/fXXWb58OWZmZkycOBEnJyf+7//+r1zl9ejRAw8PD7755hvA0E01e/Zszpw5Y3xt3ryZ3bt3ExsbW+56F8ckAkdxhBB5c0UOAM5XV13y6uTvDMCJ2BwUIP3sOW698y635swtdRnmWjWz+jbFwcrwrUOvVzgTWnwXlM7HB5+1a3CZPo06772PuNOHqeTklO+DSFI1McXUsWVJ21rQlClT8q3JyO3+mjRpEsOGDTNOrRVCsHz5cj7//PNSj8kU9Prrr7NgwQIOHTpEcHAwkydPxt3d3fjq168f/v7+rF+/vlzll8TkU8cKIdYArTF0Vd0AJiiKcqu4eyoqdWxxFEXhoQ9/Iyopg2W/fYxPkmEfK2FpSaOTfyPKOCtDURRmb7/AuuMhfDSwBYPbeZfp/ltz5qBPTMLtnZloHB3LdK9UO8nUsVJRan3qWEVRRimK0kJRlJaKovQrKWhUFSEEHe90V51xuTvTQ0lNJSs8vFxl2lloydErvL7pHMsOBZR67UZ2dDQJ23eQuHs3gb37kLBrl1z3IUlSpTH5wGHKOt7prrrQvgdaLy90/vUByLh6tcxlCSGY/kQjY97yj/ZcZubW82Tn6Eu4EzQuLtTbthXLhx8m5/Ztbk7/H2GTp5AVKdd9SJJU8WTguA9dGhgCxym9LXX37sO6s6EPM+PqVRJ//bXInB3FGXdnsFynUfHD8RCeW3WSpPSSB8B13t7U/f473N+ba9gw8cABAvv0IX5z0bNQJEmSykMGjvtQx86CRm42pGbmcPJGHGYNGwJwe8NGwl+eys0ZM8pVbt9WHqx/8SEcrXQcvhrN/L1Fb66WlxAChyFDqLdzB9Zdu6JPSiJV5jeXJKmCycBxn7o1Mkz9/f1qtDFwZEcaBsozrl5D0Zfc1VSYtj6ObJ3UiZ7N3Hi9Z+OSb8hD6+6O17KleHzyCa5vvWl8PzMsDP2dRUySJEnlJQPHfep6J3AcuhKNmX99yDObSklLI/s+9peq62TJ16PaYWdhmHKblaPnaEDp5mULIbDr0xuNg2GhvZKZSejEiQQ9PYDUv/8ud52kmkVfzi8uUu1VERNnZOC4T+18HLHSqbkSmUREuoKuwKr1zBs3KuQ5iqLw7tbzjPj2GN8cLv2Mq1xZkZGQnUNmYCDBo0Zz85135LYltZyVlRXh4eFkZmbKWXYSgHHreHNz8/sqxyS2HKnJdBoVnfyd+eViJL9djuKJ7o8Rv34DOn9/0s+dI/NGMFYPP1whz/JxskJR4MPdlwmMTuG9/s3RaUoX+3Xe3vht30bsN8uJ/fprEjZtJvnAQdzefgvbPn3yJceRagcvLy9iYmIIDg7OtyeU9N9mbm6Ol5fXfZVh8gtVfSXDAAAgAElEQVQAy6MqFgDm9ePJUN7YdI6uDV1Y9Vx79JmZxK1cRfSnn+I4dixuecYZcn/f5f2Hete5W0z78QwZ2Xra+zqy9Nk2OFkXnV2wMBmBgUTMnmPssrLt3RvPhZ+Uqz6SJNUetWYBYE3QvbErQsDRgFiSM7JR6XTofHwAQ1dV8uHDZFy/jj4jg8CnenNz+v9KKLFovVvW4ccJHXCzNePEjTj6f/VnsbvrFsasXj3qrl5FnQ8/RG1nh1XHDuWujyRJ/z0ycFQAJ2sz2tZ1IDNHz6ErhkyAujs5j1OOHSN0/ATCX3vNkLcjKIjkYrKZlUYrb3u2T+lMKy87wm6nseRg2deLCCGwHziAenv3YDdggPH92+vXk7R/v+wTlySpSDJwVJAeTd0A+PViBAA6H8MguZKeDkDG9QDSzv0LgD4lBX1q6n09z83WnI0TOjCpW30+HNii3OVoHByM+2pl3bxJ5EfzCZvyMqETJpAZHHxfdZQkqXaSgaOC9GxmSCfy68VI0jJzUJmbo/HIs5OnopC4b6/xMDsm5r6faa5V80avxlibGeY4pGflsPi3a6RnlW+nXI2rK66vv47KxoaUw0cI7NOX6MWL0ael3XddJUmqPUoVOIQQxW63KoRQCyGKz5tay/k6W9HK256UzBz2XzIsADS7013FnYHwtJOnjNdnR0dXeB3e23mRT3+9yrBvjhGVmF7m+4VGg+OzI6m/Zzd2AwagZGURs2QpgX36knTgQIXXV5Kkmqm0LY5oIYRr7oEQ4h8hRN75XM7Af35V2dOtPQDYdsawO67juHHYPPEEjqNH33NtdvT9tzgKevYhHzztLTgTGk+/L//k37CEcpWjcXbGY96H+PywDrPGjckKDydu1Wo57iFJElD6wFFw7qg/UDDn4X9+IUCflh6oVYLfr0QTl5KJdZcueC1eVOispcpocTT1sGXblE6083EgIjGdwV//xa5z5d+F3rJNG/w2/YTbzJm4v/uOcQpxVkQEOcn3ZmmTJOm/oSLHOP7zX0ddbMzo0sCZbL3C9jN3c3KYNWp0z7XZMTHkJKegTy97l1JxnK3NWPfiQwxu60V6lp7JP5zm01+voteX73+P0GhwHPUsZv7+gGEdyq0ZMwl88knif95a7r24JEmqueTgeAUb3NaQuW/D36HGrh2NmxsqW1vDBbkzmEJDCezXl5AxYyu8DmYaNQueack7vZugEhAQnUxFLQzXJyWRk5xMdnQ0t95+mxtDh5H6zz8VU7gkSTVCaQOHQv4WRcFj6Y7Hm7riYKnlckQS/4YbxhiEEJjf2TnXvHlzAFKOHiX75i3Szp5FySo530ZZCSF4oUs91r3wMJ8808rYzXS/4xRqW1t8N6zHY/5HaFxcSP/3X4KHjyD89TfIioioiKpLkmTiyjLGcUwIcVUIcRWwAg7kOf6r0mpYw5hp1Ax4wDBvYMPfocb3bZ54ArRa7AcNAiDn9m3jucoY78jVob4TFjo1AGmZOYz89jiHrt7f84RKhV3//tTfuweniRMQOh2JO3YQ9PQAOXVXkv4DSrvJ4dxKrUUtM6y9N9/9GcS2f8KZ8VQTrM00OI4ehePoUWTdunewOisyEq2HR6XX64cTIfwVEMuxwFhe79mYiV3r3dfmhiorK1xffRX7Z54hasHHmPnXR2VhAWAY+xBCbp4oSbVQqQKHoigycJRBQzcb2vs6cuJGHD//E86oh32M5zROTvdcn11FucHHdfQlKT2Lz/dfY/7ey5y/mcDHz7TEUnd/myTrvLzwWrwo30B5wtZtxG/ahNsbr2PRuvX9Vl2SJBNyX4PjQoguQohBJS0Q/C96toMhWKw7FpxvXEHodKjt7fNdmx0VWSV1UqkErz7ekG9GtcXaTMOuc7cYuOQvQmLvb/uTXLlblyiKQtyqVaSdPs2NYcMJe/U1MkNCKuQZkiRVv9KuHJ8ihHinwHvbgEPAT8A1IUTZ8pvWcr2aueNsreNyRBJ/Fcjap3FxyXecFVk1gSPXE83c2Tq5I/WcrbgckUTfL/8g7HbFBA8wDMz7rF2D0/jxCDMzkvbuJaB3HyLnzSM7z9iOJEk1U2lbHKMB41dGIUR/4ClgFPAgcA2YUeG1q8F0GhVjO/oC8N6Oi2Tl3O3G0bg4G3640/9fVV1Vefm72rB1Sicea+xK9yaueNpbVGj5ahsbXKe9Rv29e7B7+mnIziZu1WoCnuhJ+sWLFfosSZKqVmkDR30g72T9p4CdiqKsUxTlFDATeKSiK1fTvdClHt6OFlyJTGL10bs7zea2OCxatQIgu4pbHLlszbV8O7od8wa2MA5ih8alkpRecdODtXXq4PHRPPy2bMaqYwc0Tk6YNWhQYeVLklT1Shs4LIC82YIeBg7nOb4GuCLlY65VM7tPMwC+OnjduGutTc9e6OrXx3GMYQ+r7Kiqb3HkUqkEZhrDdN3UzGyeX/U3/b78kysRSRX6HPMmTfBesQKf9T8gtFrAsHo+ePQYUk6cqNBnSZJUuUobOMKAlgBCCAegGXA0z3kX8gcW6Y7uTVxp5mFLXEomu/81TMW1eexR6u/aiVWXLgBkRUWZxAaC8alZqIQgKCaFp7/6k63/hJd8UxkIIdA4OBiPY7//ntQTJwgZPYaQ8eNlF5Yk1RClDRwbgcVCiEnAKiAUyPs1sR1wpYLrVisIIRh9Z4bVqqP5EyOpra1RWVqipKWhT6rYb/jl4WFvwc+TOjGwjSdpWTm8uvEM7249T0Z2+fJ7lMRl8mScp76MysqKlMNHCBo4iPBp08gICqqU50mSVDFKGzj+D8MMqv/DsDPuSEVR8u5uNxzYVcF1qzX6tfLEzkLL2dB4Tofkn1WkcTNkDqyucY6CLHRqFg5uxYcDWqBTq1hzLJihXx/jZnzFrwhXWVriMmkS9ff/iuPYsYYV6Lv3ENinL3GrV1f48yRJqhilChyKoqQrijJWURQHRVGaKoryV4Hz3RRFWVA5Vaz5LHRqRjxkSCU7d/sFcvLsVKtxNQwNRS/+wmSSJQkhGPFQXX6a2MGY3+OPaxWfPySXxsEBt7fepP4v+7AfPBiEME4ckCTJ9JjE7rhCiMFCiAtCCL0Qol2Bc28LIa4LIa4IIXpWVx3v1+RH/XG3NedsWAJrj+WZYeVmCBxJv/5K2NRXyImPr64q3qOVtz07X+7MrD5NGdzOq+Qb7pPW3Z0677+H/2+/5Qsc4dP/R/TixeSYQHeeJEmlXwD4TWle91GP88BA8s/UQgjRFBiGYTC+F7BECKG+j+dUG2szDXP6GWZYfXHgmjE/hpl/nqmp2dkkHzpUYlm5g+lZN28S8FRv4jdvqZQ6AzhY6Xius59xuu71qCQmrztNfGpmpT1T63Z3gl7G9esk7tpFzJKlBDzeg9gVK9CnVtxiRUmSyq60LY4XgCcwjG80KOLlX95KKIpySVGUwgbX+wMbFEXJUBQlCLgOtC/vc6pbz2ZueNpbEJOcadxy3WnsGHzWrcX1rTcBSNr/W7FlpBw/wfVHuhLzxZekHD1GZmAgib/sq/S653p7y7/s+vcWfb74o9ypacvCzN8fn3VrsWjXlpyEBKI+/oTrj/cgdsV3MoBIUjUpbeDYBtQBcoClQA9FUR4t8HqsEurniWEGV66wO+/dQwgxXghxUghxMroStym/H0IIujUyLP47eMWwdkPodFi2bYttT0MvXPKffxabFTD1+DEA0s7/S3a0oQx9/L3/gCcfPlwp+TE+G9qall52hN1OY9DSv1hTYC+uymDZti0+a9bgvfwbzFu2JCcujqiPPyagTx+UzMpr+UiSVLjSDo4PAHyB34GPgHAhxAIhRKmXAAsh9gshzhfy6l+eihdSx28URWmnKEo7lwJ7QZmSRxsZumF+v5I/uGnr1MG8aVOU1FSiF39R6PbrABnXrgGQHRFpXDiYk5h/CU36lSuEjp9AxOw5FVx78HKw5KeJHRj5UF0yc/S8u/U8U374h8QKXG1eGCEE1l264LtxA97ffI15y5bYPP44QqcDQMnJkS0QSaoipR4cVxTllqIo/4dh+5Exd/77rxDioBDCvBT3P64oSvNCXtuKuS0c8M5z7HXnvRqro78TOrWKs2HxxKXk/7Zs06sXAHHffUdg335kBN67niH96lXAMH03KzdwJORvcWTdvGn4b3TlrEg306j5vwEtWDz8Aax0anb9e4shy47mmy1WWYQQWD/yCL4bN+A6fbrx/cTdu2UXliRVkTLPqlIM9gLLgGNAF6DEwFFO24FhQggzIYQfhrGUGr0/haVOw0P1HFEUOHItf6vDadxYPD75BMt27dAnJxP+ylQyQ0KMeS70qalkhRh67nISEsgKDjH+nLe7SJ+cbPhvSkqlfpZ+rTzYObULTerY8lwnP9SqqkvaJIRAZWZmPE4+dNjYhXX98R7ELFt2T0tMkqSKUabAIYSoI4SYIYQIBNZgCByNFEW5rzmkQogBQogwoAOwSwixD0BRlAvAj8BFYC8wWVGUylnGXIU6+xt2xz1aYLt1odVi16c3XsuWoatXj4xr1wl4oidX2z9E8LhxJO7dB3kCREZAgOGHnJx8QSJ32mpVfPP2c7Zi2+RO+abr/hUQU+ldVwV5fLzA2IWVExdH9OeLuP7oY0QtXEh2TOWtQZGk/6LSTsftI4TYCgQB3YA3AW9FUd5SFCXgfiuhKMrPiqJ4KYpipiiKm6IoPfOc+z9FUeoritJIUZQ99/ssU/BwPUMWwONBcYWeV1tb4b10CdaPPYbaxRl9cjKpR49x691381+YJ+NeTp4Bcn2SocWhpFRNl41OozJO170WmcTzK0/SZ3HVzLrKlbcLq+53K7B8+GH0KSnELv+WpP37q6wekvRfUNqcoduBYAxbjgQAWmBwwXzSiqL8UKG1q6WaedhibaYhKCaFiIR03O3u7enT+fjgveQrwJDoKWjAQHLiCg80APrEBHInnOmTDF00+tRUFL3emJmvKug0Kuq5WHHhZiKDlv7FzN5NGN3Bp8pyjwshsOrYEauOHUk7d47b6zdgN2CA8Xzi3r2Y+ftj5l/u2eOS9J9Xln9RfIC5wNoiXmsqvHa1lEatop2vYZfY40GxJVwNWjc3HEePMh7rfH3vuSbvAHnOnRYHgJJW8XtMFcfHyYrNL3Vk1MM+ZObomb39Ai+tPU1CWtV2XQFYtGyJx7wPjWMhOYmJ3Jr5DoF9+hI6eQqpp06ZxK7EklTTlHY6rqoUrxq5oru65HZXHQssOXAAOIwYgcrKCoTAumvXe87nDRx5d9qtjhlG5lo17z/dnK9GtMHaTMPeCxE8tegIZ0OrdzsVJTsbu/79ETodyb/9RvDIZ7kxdBiJu3ejZGdXa90kqSYpVVeVEKJU2f0URTlc8lUSwEN+jsC9A+RFUdvaUnfFt2RFR0OOHlatync+7xhHTnKewJGSAtW0rqV3yzo097Rlyg//cDUyCUtd9X630Dg64j7rXZwnvUTcunXEr99A+rlzhE+bjsajDn6bNqFxdKzWOkpSTVDaMY7fAQUorKNayfPf0pb3n9fC0w4bcw03YlMJjk3Bx8mqxHssWrfGAkj95597zmVHRXLr3VnYPvUk+sTqbXHkldt19W94Ag3cbABQFIXo5AxcbSprFnfxNM7OuL7yCs7jx5OwbRtxK1ehdnDIFzSyY2LQODtXS/0kydSVdozDG6h75795X34YVpKnU8MX5lU1jVrFIw0NLYEDl8u2UE/r7n73Zy/DNNiE7TuI/+knYr7+Jn+LwwQWw+k0Ktr63M38t/l0OI9+/DubT4VV6xiDysICh2HDqLd7F15fLDa+n37lCte6diPstdfkOIgkFaK0YxzhBV/AA8BuYBLwHtCwEutZKz12Z/uRsgYOjbMz3JkpZdbAsOtLVlgYYMhfrs8zOG4KgaOg44GxpGTmMP2ns0zdcKZaBs7zEipVvtZF2pmzIARJe/YSPPJZggYM5PaPP5rk71KSqkOZ52kKIdoIIQ4AW4ADQANFUeYripJR4bWr5bo1ckEIOB4YR0pG6QdnhVaLxskwuJ4bOHJlx8TkHxyv5NXj5bHgmZYseKYlljo1O87e5KlFRzhRxJqW6uAwdAj++3/FacIE1I6OZFy+TMSs2Vzr2o2oRYuqu3qSVO1KHTiEEN5CiLXA30A80ExRlJcVRZHLcsvJydqM1t72ZObo+eN62X6N9sOGYvnww1g++GC+9/WJifm+GZvit2QhBEPaebNrahdaetkRHp/GsG+O8sm+K2Rm60suoApo3d1xfe1V/H8/iMeC+Vi0aoU+KSlfoi0lOxslp8ZvZCBJZVbaleMfAVcwbGz4iKIoAxVFuVapNfuP6N74TnfVpbJ1V7lMnozPyu/RODsVe52+ilaPl4efs2HgfFK3+ijALxcj0JvYeIJKp8OuXz98N27Ad/MmnJ5/3ngucdcuAp7oScyyZWSZSM54SaoKpZ0F9QaQBiQDs4taBawoyhMVVK//jMcau/HJL1f57XIUer2CqowbBart7Io9r081va6qvLRqFW/0aky3Rq5Y6tSYaw1TdlMzs9GpVWjUJpHdGACLZs3yHSf9doCs8HCiP19E9OIvsO7SBfvBz2DdtStCq62mWkpS5Stt4FjN3Wm3UgVqUscGDztzbiakcy48gdbe9mW6v8TAYcItjrza++VfP/HOz+cJik1h4eBW1HOxrqZaFc/z889I+fNP4jdtJunAAZIPHSL50CHUzs64TJ6Ew/Dh1V1FSaoUpQociqKMreR6/GcJIejexI01x4I5cCmyzIFDWFqCVgtZhc9MMsUxjpLcTsnkaGAstxLSeWrxEd7s1ZgxHXzL3BqrbEKlwrpLF6y7dCE7Lo6EbduJ37SJzIAAEHdbSjnx8QgzM1QWFtVYW0mqOKbTD/Af1r2JYZxj34VI9GVMhiSEMLY6VIW0Pmpi4HCw0rH31UcY2MaT9Cw9c3dcZMS3xwiNM93PonF0xGncWOrt3IHP+h+w7dPbeC5m6TKuderMzTffIvnPP+WAulTjycBhAjrUd8LRSseVyCQW/Vb2OQdqW1sArNrfnWGVm1LVFKfjloadhZZPh7Tm61FtcbbWcSwwjic+O8x3f9ybFdGUCCGwfOAB1NZ3u9cyQ0LQp6aSsG0boc+/wPVujxL50XzSL16UiwulGkkGDhNgplHz2dDWqAQs+u3aPZkBS2LXry/mzZtj88TduQkaNzegZrY48urZzJ19rz5Cv1YepGXlEBCdXPJNJsZ76RLq79uL85QpaH3qkh0dTdzKlQQNHETMF19Wd/Ukqcxk4DARXRu6MKmbIUfE9jM3y3Sv88SJ+G36CV3dusb3tLUkcIBhvcvi4Q/w/dgHeevJxsb3b8SkkJFdM7p9dD4+uEyZTP29e/HduAGHkSNROzhg1bmz8ZqkgweJW72arIiIaqypJJVMbkpoQno0dePLg9c5FXK7XPdr8uyCa2xx1NCuqsI8emfNC0BaZg5jvj+BTq1i/jMtaVPXoZg7TYcQAotWrbBo1Qq3t94Ezd2/grfXrCXlr7+I/HAeFq1bY9OrJ7ZPPIHWw6MaayxJ95ItDhPS1MMWc62KwOgU4lIyy3y/Os9+S7Wlq6ootxLSUAnBtahkBi39i7k7LpBchm1bTIHQavNlRrQfMhibHj0QZmaknTlD1Efzuf5Yd4KGDjXkm5ckEyEDhwnRqlW09DJMx/2nHK0OlU5nnGGlda/dgaOeizV7XunCxK71UQnB93/eoPvC39l57maNHXC27dULry8W0/CvP/H87FNsevVCWFiQfvYcOfF3/zxkhoaSduFCjf2cUs0nA4eJye1yORVcvu4qtYuh1aFxM2y9Xpu6qgoy16p568nGbJvciVbe9kQmZjDlh3+Y/tPZ6q7afVFZWWH75JN4ff4ZDf/8A89Fi/JNfLi9dh03Bj3D9W6Pcmv2HJIPHUKfIfcYlaqODBwmJjdvRXkDh0WrVqDVYt6sGQiBkp5e69cNNPe04+eXOjJvYAvsLLQ8lmcspKZTWVpi2/OJfEmmVLY2aFxdyY6MJH7jRkInTOTqwx0InTyFxH2/VGNtpf8KGThMTJu6hq6qs2HxpGeV/R/8Ou+/T8M/jqDz8jSuVNanpVVoHU2RSiUY3r4uh19/lN4t6hjfX/FHEL9dql0bELpMnoz/od/x3bQJ58mTMW/aFCUtjeTffiP1xAnjddmxsaT89ZdsjUgVTs6qMjFO1mY087Dlws1EDl2Npmcz95JvykOoVMZxDmFlCamp6FNS8y1Iq83sLO9uLhgQncy83ZfI1it0b+zKzN5NTHbfq7ISQmDRvBkWzZvh8vIUsiIjST74O+bNmxuvSTpwgIh3ZyHMzLB88EGsOnXCqlNHzBo0oKiNSiWpNGSLwwT1bWWYfrn9bNnWcxSksrQEavc4R3F8HC15+6kmWJtp+O1yFE98dpj3d16s9oyDlUHr5obDsKFYNL+7g6/K3AKzJk1QMjJI+eMPoubPJ6hff6537catuXOrsbZSTScDhwnq09LQ1fLbpcgyZQYsSGVlBdTemVUl0ahVPN/ZjwP/68rQdt7kKAor/gii28cHWXP0Rq2flWTXtw/1ft5Cgz+O4PHxAuz690Pt7Ex2VBSZN24Yr1Oysrg5Y6Zhg8bg4Fr/e5Hun+yqMkFeDpa09XHgVPBt9l+KpH9rz3KVY2xxmHhOjsrmamPO/GdaMqqDD+/vvMjxoDgOX4thVAff6q5aldA4O2PXty92ffuiKAoZV66g5Bn3SL9wgYQtW0jYssVwvasrlu3bY/ngg1g80Bozf3+ESn7HlO6SfxpM1NOtDd1V646HlLsMjZNham7GpUv53s++fZuEHTtQ9KaRprWqNPe0Y8P4h1n2bBtmPtXE+P6FmwmcCY0v5s7aQwiBeePGhtl3d2g8PHCbORObHj1QOziQHRVF4s6dRMyeTVC//mTeCDZemxEQQE5CQnVUXTIhssVhoga08WLB3iucCIrjfHgCzT2LT9hUGNveT5G0bx+3f/oJh9GjjQOike9/QOLu3YDArm+fCq65aRNC0Kv53VlXiqIwe9sFTgbf5snm7kx/ohH+rrVjAL20tK6uOI56FsdRz6Lo9WQGBJBy4gRpp06TERSEzs/XeO3NN94k/cIFdPXqYdG6NRatW2HRvLmhVXJnR2ap9jOJFocQYrAQ4oIQQi+EaJfnfV8hRJoQ4syd17LqrGdVsjbTMORBbwC++7N8W4nbPPooamdnMq8HkPbPGQD0mZkk//47AOnnz1dIXWuybL1Cez9HzLUq9pyPoOfnh3lr8zluJdT+KcyFESoVZg0a4DhyJJ6fLqTez1uMXzgUvR6VlRVCpyMzMJCELVuImDWboIGDuNK2HbErVxrL0aeno2SWfdscqWYwicABnAcGAocLORegKErrO6+JVVyvajW2oy8qATvO3iQ6qexz8YVWi/2AAQBEffIJ6ZcukXr8uHGwPOP6dfQpKSTt31/rFwkWJTfn+aHXH2V4e8Puwhv+DqXrgt+Zte18ufYMq62ESoXP6lU0Ovk3vhs34Pb2W9g+9RQ6Hx+UrCw0znc32UzYvp0rbdsRNOgZbs2aTdy6daT+/bfs5qolhCnNoBBC/A78T1GUk3eOfYGdiqI0L+a2e7Rr1045efJkhdevOry4+iS/Xozk9Z6NmPyof7HX/noxkuaettSxu5uiNDMsnKCnn0afnAxCoKtfj8zrAYBhENSmZ09ur1lDnY/mYf/005X6WWqCgOhkPv3lKrv+vYW1mYY/3nwUe0vZBVOSnKQkhFptnJARtWgRsUsL7yAwa9CAeju2G48zAgPRenmhkl1d1U4IcUpRlHYlXlcDAscF4CqQCLyjKMqRksqpTYHj8NVoRn93Ak97Cw6/8SjqIvJubzoVxv9+Okt9Fyt+m94t37ms8HBiV6zg9g/r77lP7eJMTnQMDqNG4T5zRmV8hBrpSkQS16KS6NPSMEkhIzuHz/dfY9TDPnjYy9zhpZGTnEzGpUukXbhAxtVrZFy9Ssb165g3a4bvurWAYSrw5TZtQa9H5+uLWYMGmNXzQ+fnh87XDzP/+jJXexUqbeCossFxIcR+oLBl0DMVRdlWxG23gLqKosQKIdoCW4UQzRRFSSyk/PHAeIC6eRIa1XSd/Z3xdbLkRmwqBy5H0aOpW6HXbToVCkBA9L1Tb7WenrjPmoXawZGYr75C41EHjYMj6RcukBMdA0BmkGmnZK1qjdxtaORuYzz+6WQYS38PYPnhQPq39mRC13o0dLMppgRJbW2N5YMPYvng3ZTGSk4OOYl3//pmx8Wh8/QkMySEzIAAMgMCSMpThuenC7F96ikAUo6fIOPyJUNQ8fND6+GBUKur6uNIeVRZ4FAU5fFy3JMBZNz5+ZQQIgBoCNzTnFAU5RvgGzC0OO6vtqZDpRI8+7APH+y6xIo/AosMHNejSl6r4TxlMmYNGqDzqUvc6jWkX7hgPCcDR/EerudI31Ye7Dp3k82nw9h8OozujV2Z0LU+D/o6yC08Skmo1Wgc7ibd0rq5UX/vHvTp6WQEBJB5/ToZQUFkBt0gMzAQXf273bNJ+/Zx+4cf7ham1aL1qIPO0wvzFi1wfe1V46mc5OT/zDY71cGkp+MKIVyAOEVRcoQQ9YAGQGA1V6vKDX3Qm0W/XeNYYByngm8bd9DNlZmtJya55MFzIQS2vXoChn7mvLJu3kSfkYHKzKziKl6L+Lva8MXwB3j9iUZ8+0cgG/8O5bfLUfx2OYpBbbxYOKRVyYVIRVKZm2PRrBkWzZoVeY1lh4dRFD2ZgUFkBgWRHRVFVnAIWcEh6DPv/vnXZ2Zy9cH2qGxt0Xl5ofX2RlunDto67mjc3LFs80C+bJlS2ZlE4BBCDAC+AFyAXUKIM4qi9AQeAd4TQmQBemCioihx1VjVamFjrmV0Bx++OhjA0t+v8+2YB/Odv3jrbtNfJUCvV1AVMRdFoPgAABtOSURBVBaSK2/gEObmKOnpZAYHY96wYcVWvpap62TJe/2b80r3Bqw6GszqozfoWN/JeD46KQO1SuBoJQd6K5ptjx7Y9uhhPNanp5MVHk5maChCe3dzy+yoaIS5OfqEBNITEvK1rAG8vvwCm8cNHSC3N/5I4o4daOrUQevujqaOO1r3OmjcXNG4uKB1rT1b9FckkwgciqL8DPxcyPubgc1VXyPTM66TH98eCWL/pSgu3EygmcfdBYEnb9yNpXoFkjKysbPQFlaMkXmTxgitFo2LC7oG/qQcOkzmjRsycJSSk7UZ03o0ZGLXemjVd2e1f3ngGuv/DqV/Kw/GdPQt18JNqXRU5uaY1a+PWf36+d7XeXnS6PQpcmJjyQwNJSssjKxbEWRH3CLrVgQ6X1/jtRlXLpNaxEQarU9d/PfdTdkbNvUVVFZWaJyd0bi4oHG5819nZzTu7qjMzSvlc5oikwgcUsmcrc0Y+ZAP3/0ZxOLfrvH1qLsTH04XSDObmJZVYuDQODvjs3YNajs7bm/YaAgcQTcqo+q1mqUu/1+h2JRMMrP1/HQqjJ9OhdGmrj3D2teld4s6WJnJv25VRQhh+Afd2RkeeKDI65zGj8emRw+ybkWQFXGL7FsRZEVEkB0djdbz7h5x+owMkn4pOkmW+5w5OAwbCkDir79y+4cf0Dg4oHZwRO3ggNrRwXhs+VD7Gj8mJv8k1yATu9Zj3fFg9l2IzNfqOBdmWFSlVQuychQS0rLwLkV5ufsV6fz8AEg7fZrEfb9g0/0xsiIiiVm6BJdJk/L9BZKK9+WINkx/IoU1R4P56WQop0PiOR0Sz9ztF/i/AS14+gH5uzQlWnd3tO4l57wRQuC1bCnZ0dHkxMSQHR1NdnTuf6PRuN4dM8kMDCL16LHCy7GwoPE/p43HQYOHkB0bg9rWDrWNDSo7W+PPVp07Yd2lCwA5CQlkBASitrNFbWuLys6uWte9yMBRg7jamhtbHcsOBfLF8AdISs8i7HYaOo2K1l72nLgRR3xq2fJN5Dbdkw8dIvnQIZwnTSIzOJjEXbtQ/X979x4fV1UtcPy35p1k8mjSNGnTlCRtaWlLKbW0BQqCRSiiVFCwFB8IWB+gcn0gWBXUC1evXhU+ICqiaC1SuRYKAgpUQa61lLb0/X6kpE1feTTvZDIz+/5xTiaTNGkzaTKTZNb385lPZs6cOWdlz5lZc/beZ++0NPK/qdd3xKJ4eBrf+dAkvnrl2by4+TDL3i5j3YFqxkZNIrXraB1ZqW5GpCdP9cZgJh4P6Zdd1qN1M+dfi2/yZELV1YSqqwhWVRGqPkGoqgo6jTLcWl5OqLKSYPnhk/eZmhJJHE0bN1K26LMnxeRIT8fhT+Os3y/BnRe/9hhNHIPMrXOK+O2q/fxt6xFONAbYe7wegPEj/JEG2VgnKvKWFHd4XL1smXWlOdC8bVsfRJ2c0rwubpxRyI0zCtlf0UBRTmrkucXPbmbdgWouHjeca88bxbwp+aT7Tl29qAaHnp7FAIx9+SVCtbWEa2sJ1dYSqqklXGf9TZnW3lNPPF58500lXGOvV1uLCQQIVVYSqqzE4Y3v2YcmjkFm9LBU5owbzpu7K1ixoTxyJfmE/HQ8diPtiabYxldy5eaS9817weWieulTBPbujTzXsm07JhzW+RjOUPHwtMj9lmCIrFQPTofw5u4K3txdweLntnDFOSO49rwCLpuQi8+tF7YlA2eGVfV0OmmzZ1G8bFnksTEG09JCuK6OUH09jh5soy/pt8EgdOMMqwVj2dtl7DxiXWd7Tn5GpEG8N1OjZn/yk2QvXMiwj32sw/JwY2OH+Riad+xgz/vmUvvqq70NP+l5XU4e/+QM3l58Bf91/bnMLsmmNRTmpc1H+Nwf1vHipvZqi4E0JJAaOEQEh8+HKzcXb3Fx3H/Y6RnHIHTl5DyyUt1sO1zL0dpmwDrjaC23JmaqibGNI1rmh+dz/JFHELcb34SzaVj1b5q3bYtUZ717622Eqqo49KUvk7Fdq7HORFaqh5tmjuGmmWMoP9HEXzaV89LmI1xxTvvoAN99YRullQ3Mm5zP5RNHkJehbSIq8TRxDEJel5ObZ43h0X/spdIe9nviyHTKqq3h0ntzxtHGmZFBybPLweHgxPLlVuLYupXMD14DYDXwQdxPjYe6UVkpLLp0LIsubb8mwRjDy1sOc7S2hdd3HgdgYn46l00YwWUTcnnPWcM6XEOiVLzoUTdIffriYnxu6+3LTvOQ6/dGqqpi7VXVmbugAPfIkfgmTQKgcf066t/8P4KVlZF1vCUlZ7QPdXoiwotfuoQfXH8ucyeOIMXtZMeROn7xxl4W/Go1j/x9T2TdUFirtFT86BnHIDXc72XBBWN4clUpE/LSERGyUnrXq6o7vknWuEHNGzdR9pnP4Im6QjdZJ36Kt+F+LwtmjmHBzDE0t4Z4u7SKN3Ye5/Vdx7n07OGR9R5/cx9L3zrA7OIcZpXkMLskm9HDUk+xZaV6TxPHIPbF942jujEQaSyPnHH0UeJwjcglbc4cmjZvJtzQ0KG3Vbiu7hSvVP3B53ZyyfhcLhmfy7fo2HC+4d0TlFU1UVZlXbEOUJCVwuySHN43cQTXTB3ZzVaVip0mjkEsx+/loQXtwylkpVqJo7aPEoeIMObXjwNw9Ec/ouqJ30Sea7vOQyVO9LAVj948ne2Ha1m9r5LV+6pYs7+SQyea+PP6gzS1BiOJo6axlSf+tZ/zC7OYVpjFMB2MUfWCJo4hJCPSxtH382QP//znqX3pZYIVFdDaSqjh9PN/qPhxOoQpBZlMKcjk9ktKCIUNO47UsnpfFSW57deQvFNWzcMrd0ceF+Wkcl5hFpNGZjBpVAYzi7PxuvQaEnVqmjiGkHSvC4dAQyBEayjcpz1unH4/xcv/jAkE2HPZ5ZjGRkwwiLj0EBqInA5h8qjMDqMog9V76zOXFLOh7ASbD9VQWtlIaWUjKzaUA7DxO1dGEsez7xzE5XAwIT+dopw0PC7tS6Ms+qkfQhwOISPFzYnGVmqbWsnx9+2kTG0ztzn8fsJ1dYQbGnBm6rDhg8nZeeksvsbqLdcaCrPzSB2bDtaw/XAtx+qayUxtH/bkJ6/uoqyqCbAS0ZjsVMbmpjF2hJ+5E/OYWZydkP9BJZ4mjiEm004cJ/ohcbSJJI76ek0cg5jb6YhUb3VmjOG6aQVsLa9l97F6yqob2V/RwP6KBl7bfozMFHckcazaU8HPXtvN6OwUxmSnUjgslTE51t8R6d7TTiqmBh9NHENMVoqbA0BFXUuH0Vj7ktPvJwiE6hvQYfmGJhHhK1dOiDxubg1RWtnA3mMN7DlWz5xx7V2Bt5TXsKa0ijWlJ2/H53aw6b6rItVcz6wtQ0QYmekjL8NHfqYPv85TMujoOzbETB2dxcaDNby2/SizSnJO/4JecPithBSu1y65ycLndjIxP4OJ+SePGHD99NFMHpVJWVUj71Y1UlbdZP2tasTjdHRoG/npq7sor2nu8Pp0r4u8TB+fuvAsPnFhEQBHappZe6CKnDQvw/0ecvxeslLcevYyQGjiGGKum17AktUHeG5DOd+YNxFXPwxJ0Z44tEuusi5SHD6u62rR5taOF4peN72Ag9VNHKlp5mhtM4drmqlrCVJ3rJ6mqHXXv1vNnU+90+G1bXO556R5eHrRbLJSra7EKzYcorohQFaqh8wUN5mpbjJT3GSluMlIceuwLP1AE8cQc35hFiXD09hX0cCbeyq4fELfT+7i8FvdO0OaONRpdB4e/utXTezw2BhrxsrDNc3kRF1Tkp3mYd7kfCobWqisD1BR30Jtc5DjdS0cr2vpMA3vk6tKeefdE13u/8PTRvEz+1qnsqpG7v7fTaR5XaT7XKR5nfi9bvxeJ2leF9dMHRmZWOvQiSYaW4KkeV34fS7SPK7IFAZKE8eQIyJcP72AH7+yi2fWlvVL4nD60wEI12niUGdGRMhK9UTOHtrMLslhdqeq1kAwTFVDgKqGQIeziA9NHcWUUZmcaGqlpqmVmsYANU1WB5HoCxyP1bXw732VdOeCouxI4njk77v545qyDs97XA5S3E7OK8zi97fOBCAcNtz867dI8ThJcTvxuq11UtxOUjxOrpqcH+l8sO94PVvLa/G4rOo7r12N53E58LqcTMhPj+yrtrkVpwgelwOXQwbcHOWaOIagj7xnNA+t3M1ftxxhz7F6xo3o20bySFVVgyYOFT8el4P8TKtBPdqtc4q7eUVH4/P8LL19FnXNQRpagtRH3RpagozIaK9uy07zMDY3zX4uREMgSCAYJhAM0xQIRtZrCYZPmYyKctIiieP1ncf53l+6norA43Sw64GrI48/+tgqdh21Pl8iRNqKvC4HN80cw1ftjgvbymu5Z/kmXA7B7XSQnebhsY+/p0flcSY0cQxBIzNTuGFGIU+99S4Pr9zNwzedf/oXxUCrqtRglOFzc3FUb7BT+fpVEztUqxljaAmGaW4NET0QsdspLL19Fk2BEE2tIZrtW1NriKZAmMkF7Z0JzspJ5ZpzR9ISDBMIhQkEQ7SGDIFg+KRqMK/LOmsJhMKEwta+W4Jh6oCmQHtbUE1TK5sO1kQe56b3Txf8zjRxDFF3XD6OZ9aW8cKmchZdWtJlX/3ecqbbVVX1OuyISg4igs/tPKnNxuV09DgZzT0nj7lRk3SdygtfnBO5HwqbyNlOSyjUYUiYKQUZPHfHxQRDYVpDhng1w2h3gyGqICuFT8wuwhi486n11DX3zcCHAI40u6pKR8hVqt85HUKKx0lmqpsR6b7IKNgA6T430wqzmFGUzYVjc/qtC35nmjiGsLvnTeCckRmUVjZy3/Nb+2y72sahVHLTxDGE+dxOHl14Ph6ng2ffOcSeY31zhqBtHEolN00cQ1xJrp+PzhiNMfDzf+w9/Qt6INLGod1xlUpKmjiSwOffOxanQ1ixsZzSijNv0NYrx5VKbpo4kkBhdiofmV5AKGz4zxe77kcei7bG8ZC2cSiVlAZE4hCRH4nIDhHZJCLPikhW1HP3isgeEdkpIlclMs7B7GtXTsDvdfHa9mP8fcfRM9qWM73tjEO74yqVjAZE4gBeBaYYY6YCu4B7AURkErAAmAzMA34uIjqvZS+MyPBx1xXjAfj2c1vPqHuupKSAw4FpasK09l03X6XU4DAgEocx5hVjTNt1/KuB0fb9+cDTxpgWY8x+YA8wMxExDgWfuqiIKQUZHDrRxPde6H2VlYhEdcnVsw6lks2ASByd3Aq8bN8vAKJHGjtoL1O94HY6+OmN0/C6HDyz7uAZVVm5sq3Z31oPH+6r8JRSg0TcEoeIvCYiW7q4zY9aZzEQBJb2YvuLRGStiKw9fvx4X4Y+pIzPS+frV1kDpN3//LaT5kvoKd8ka97q5q19d2GhUmpwiFviMMZcYYyZ0sVtBYCI3AJ8ELjZGNM2jNghoDBqM6PtZV1t/1fGmBnGmBm5ubn9+J8MfrdcVMSEvHTerWrksdd7d22Hb8oUAJq2bOnL0JRSg8CAqKoSkXnA3cC1xpjGqKeeBxaIiFdEioHxwJpExDiUuJwOvjt/MgAPrdzNkn+XxrwN32Tr9c1b9IxDqWQzIBIH8AiQDrwqIhtE5BcAxpitwJ+AbcBfgTuMMb2rW1EdzC7J4ZsfsIaN/vaKrSxffzCm1/smW1VVLTt3YgKBPo9PKTVwDYhh1Y0x407x3APAA3EMJ2ksunQsbqeD776wje+s2MoFRdkUZqf26LVOvx9PcTGB/ftp3r2bFPsMRCk19A2UMw6VILdcVMRVk/Oobwly17INMTWWt7VzaHWVUslFE0eSExEevO5c8jK8rDtQzWeXrKMl2LPkkTKlrZ1DG8iVSiaaOBQ5fi9/uG0W2Wke3th1nDuWru9R8vBNnYrv3HNxjyk87bpKqaFD2nu+Dh0zZswwa9euTXQYg8628loW/no1JxpbmTtxBI99/D14XPrbQqlkISLrjDEzTreefiuoiEmjMlh6+yyyUt2s3HGMO59aT2sonOiwlFIDjCYO1cHkUZn84bZZZPhcvLLtKLc++TY1TTqQoVKqnSYOdZIpBZksvX02w/0e3txdwXWP/out5TWJDkspNUBo4lBdOnd0Js/dcTET89PZV9HAdY+uYsnqAwzFNjGlVGw0cahujR6WyrNfuJiFs8YQCIX59nNbuGvZBq26UirJaeJQp5TicfLgdefy0IJppLidrNhQzryf/ZNXth7Rsw+lkpQmDtUj86cV8JcvzeG8wiwO1zSzaMk6Fj7+Fqv2VmgCUSrJaOJQPTY218+fP3ch931oEpkpbv69r5KFj7/FoiXrEh2aUiqONHGomLicDj59cTH//PrlfPX9Z5Od5mH6mGGJDkspFUcDYnRcNfhkprr54tzx3HZJMYIkOhylVBxp4lBnJNWjh5BSyUarqpRSSsVEE4dSSqmYaOJQSikVE00cSimlYqKJQymlVEw0cSillIqJJg6llFIxGZJTx4rIceDAGWxiOFDRR+H0JY0rNhpXbDSu2AzFuM4yxuSebqUhmTjOlIis7cm8u/GmccVG44qNxhWbZI5Lq6qUUkrFRBOHUkqpmGji6NqvEh1ANzSu2GhcsdG4YpO0cWkbh1JKqZjoGYdSSqmYaOKIIiLzRGSniOwRkXsSGEehiPxDRLaJyFYR+bK9/H4ROSQiG+zbBxIQW6mIbLb3v9Zeli0ir4rIbvtvXGd2EpEJUWWyQURqReSuRJSXiPxGRI6JyJaoZV2Wj1geto+3TSIyPc5x/UhEdtj7flZEsuzlRSLSFFVuv4hzXN2+byJyr11eO0XkqjjHtSwqplIR2WAvj2d5dffdEN9jzBijN6u6zgnsBUoAD7ARmJSgWEYC0+376cAuYBJwP/C1BJdTKTC807L/Bu6x798D/DDB7+MR4KxElBdwKTAd2HK68gE+ALwMCDAbeCvOcV0JuOz7P4yKqyh6vQSUV5fvm/0Z2Ah4gWL78+qMV1ydnv8f4DsJKK/uvhvieozpGUe7mcAeY8w+Y0wAeBqYn4hAjDGHjTHr7ft1wHagIBGx9NB84Hf2/d8BH05gLHOBvcaYM7kAtNeMMf8Eqjot7q585gO/N5bVQJaIjIxXXMaYV4wxQfvhamB0f+w71rhOYT7wtDGmxRizH9iD9bmNa1wiIsCNwB/7Y9+ncorvhrgeY5o42hUAZVGPDzIAvqxFpAg4H3jLXnSnfcr5m3hXCdkM8IqIrBORRfayPGPMYfv+ESAvAXG1WUDHD3Siywu6L5+BdMzdivXLtE2xiLwjIm+IyCUJiKer922glNclwFFjzO6oZXEvr07fDXE9xjRxDGAi4gf+DNxljKkFHgPGAtOAw1iny/E2xxgzHbgauENELo1+0ljnxwnpqiciHuBa4Bl70UAorw4SWT7dEZHFQBBYai86DIwxxpwPfAV4SkQy4hjSgHvfOrmJjj9O4l5eXXw3RMTjGNPE0e4QUBj1eLS9LCFExI11YCw1xiwHMMYcNcaEjDFh4HH66TT9VIwxh+y/x4Bn7RiOtp3+2n+PxTsu29XAemPMUTvGhJeXrbvySfgxJyK3AB8Ebra/cLCrgirt++uw2hLOjldMp3jfBkJ5uYDrgWVty+JdXl19NxDnY0wTR7u3gfEiUmz/cl0APJ+IQOw61CeA7caYn0Qtj66bvA7Y0vm1/RxXmoikt93HalzdglVOn7JX+xSwIp5xRenwSzDR5RWlu/J5Hvik3fNlNlATVd3Q70RkHnA3cK0xpjFqea6IOO37JcB4YF8c4+rufXseWCAiXhEptuNaE6+4bFcAO4wxB9sWxLO8uvtuIN7HWDx6AgyWG1YPhF1YvxgWJzCOOVinmpuADfbtA8ASYLO9/HlgZJzjKsHq1bIR2NpWRkAOsBLYDbwGZCegzNKASiAzalncywsrcR0GWrHqk2/rrnywero8ah9vm4EZcY5rD1b9d9sx9gt73Y/Y7+8GYD3woTjH1e37Biy2y2sncHU847KXPwl8rtO68Syv7r4b4nqM6ZXjSimlYqJVVUoppWKiiUMppVRMNHEopZSKiSYOpZRSMdHEoZRSKiaaOFRSEZEnReS1RMfRmYi8LiK/TnQcSvWEdsdVSUVEMgGHMaba/qIeZ4y5LI77/xZwuzGmqNPybCBoOg0fodRA5Ep0AErFkzGmpj+2KyIeY42q3CvGmJ6OEKtUwmlVlUoqbVVVInI/1lXK7xURY99usdfxi8hDYk0m1GiPenp91DaK7PVvFpGXRKQB+L49rMPjIrJXrIl99onIgyLitV93C/B94Kyofd5vP9ehqkpE3CLyAzuGgFgT9yzs9L8YEfmCiCwRkToROSgi93ZaZ74df6OInBCRNSJyfj8UrUoiesahktWPscYUKsYatA6gxh4L6AWsoRo+BpRjjU/0tIhcbYxZGbWNHwLfAO6wHwvW4HILgaPAVOCXWMNW3Ic1MN5E4GbgAvs19d3E9yDWUOefwxri5aPAH0TkaKcY7gO+hTX50TzgERFZY4xZKSL5WCMFf8v+68MahjuIUmdAE4dKSsaYehFpAgLGmCNty0XkMuBCrPkN2qq1fmUPEPdFrPGA2vzSGLOUjhZH3S8VkbHAF4D7jDFNIlIPhKL32ZmIpAJfAv7DGNM2RPyDInKBvf3oGJYZYx637z8qIndiJbqVWLPFuYE/GWNK7XW2d7dfpXpKE4dSHV2ANXXwIevkI8KDNYBctJNGZhWRzwC3Y00nmob1GYu1Snicvb9/dlr+BnBvp2UbOj0up30Sn03A34AtIvIq8Dqw3BhThlJnQBOHUh05gBraq5KidW78boh+ICI3YI1Eeg/Wl3wtcAPwQN+H2W1MBjtRGWNCInI11v9yBdYorj8QkRuMMX/px5jUEKeJQyWzAODstGwtkAX4jDGxzt9xKfCO6TiHSlEP9tnZHqDF3l50DO8lxjlFjNXffo19e1BE/gp8GtDEoXpNE4dKZvuBG0RkMlZjdh3wd6z5DJaLyN1Y1T3DgIuA5qj2hK7sBG4TkflYX/AfpL3hPXqf+SJyIVbVV6OJmkQJwBjTKCIPY/XUOk574/h84P09/edE5CJgLvAK1twS47Ea7J/o6TaU6op2x1XJ7AmsmR9XAceBm+xf6NcCy4GfAjuAF4FrsCbDOZVfYk1C9FvgHWAWVm+naM9h9XB60d7n3d1sazHWtKk/w0pCHwc+3qlH1enUYDX0r8BKUr/Bmlf8+zFsQ6mT6JXjSimlYqJnHEoppWKiiUMppVRMNHEopZSKiSYOpZRSMdHEoZRSKiaaOJRSSsVEE4dSSqmYaOJQSikVE00cSimlYvL/fByNmNgxmY8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.rc('text',usetex=True)nn\n",
    "#plt.xscale('log')\n",
    "#mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "long_end = 200\n",
    "x_long = [i for i in range(long_end+1)]\n",
    "plt.plot(x_long,origin_DGD_error[:long_end+1],linewidth=2,linestyle='--',color = 'tab:red')\n",
    "plt.plot(x_long,origin_PGEXTRA_error[:long_end+1],linewidth=2,linestyle='--',color = 'tab:blue' )\n",
    "#plt.plot(x_long,origin_NIDS_error[:long_end+1],linewidth=3)\n",
    "\n",
    "x = [i for i in range(num_layers+1)]\n",
    "plt.plot(x,pred_DGD_error[:num_layers+1],linewidth=2,color = 'tab:red')\n",
    "plt.plot(x,pred_PGEXTRA_error[:num_layers+1],linewidth=2,color = 'tab:blue')\n",
    "#plt.plot(x,pred_NIDS_error[:num_layers+1],linewidth=3)\n",
    "\n",
    "plt.legend(['Prox-DGD','PG-EXTRA','GNN-Prox-DGD','GNN-PG-EXTRA'],loc='upper right',fontsize='large') \n",
    "plt.xlabel('iterations',fontsize= 'x-large')\n",
    "plt.ylabel('NMSE',fontsize= 'x-large')\n",
    "\n",
    "figure_name = \"D\"+str(n)+\"M\"+str(m)+\"NO\"+str(nnz)\n",
    "plt.savefig(\"./error_fig/noise1/\"+figure_name+\".eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
